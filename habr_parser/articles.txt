{
    "articles": [
        {
            "title": "Тёмные паттерны Amazon",
            "text": "Сегодня я попытался оставить отзыв на Amazon (с мобильного приложения) о продукте, который купил в начале года, но который в итоге перестал работать. \r\n\r\nЯ зашёл в приложение, прокрутил свои заказы, нажал на ссылку с купленным товаром — и на кнопку, чтобы оставить отзыв.\r\n\r\n\r\n\r\nПотратив 5−10 минут на написание отзыва, я увидел такое сообщение:\r\n\r\nДля этого товара допустимы только подтверждённые отзывы о покупке (Amazon Verified Purchase Reviews).\r\nСтолько времени впустую! Но я же купил эту вещь, Amazon знает это, и что такое «подтверждённые отзывы о покупке»?\r\n\r\nОбратите внимание, что это сообщение пришло только после попытки оставить отзыв на 2 звезды. Что если бы я оставил более хороший отзыв? Это разрешается?\r\n\r\n\r\n\r\nВсё потому что это товар Amazon's Choice, который они продвигают? Каким-то образом 2660 покупателей смогли оставить отзыв, но не я...\r\n\r\nAmazon и другие манипулируют системой отзывов\r\nЯ очень часто встречаю на Amazon явно поддельные отзывы или отписки. Все последние отзывы на 5 звёзд по смыслу бесполезное восхваление. Например, взгляните на этот товар.\r\n\r\nПрокрутите вниз, чтобы прочитать отзывы. О, интересно: похоже, два или три человека поставили 1 звезду, но остальные 72 человека — идеальные 5.\r\n\r\nПогодите, это настоящие люди? Давайте посмотрим на три самых последних отзыва:\r\n\r\n\r\n\r\nИнтересно! Все трое — Джефф Р., Лорен Берлсон а также Анонимный покупатель Amazon — оставили отзывы об этом «Ультразвуковом отпугивателе насекомых, набор из шести предметов», а потом все они оставили отзывы о «Компрессионных носках для мужчин и женщин»! Удивительное совпадение!\r\n\r\nЧто ещё они покупали?\r\n\r\n\r\n\r\nНевероятно, но те же три человека (предположительно, купленные) одновременно оставили отзывы для трёх, казалось бы, несопоставимых продуктов на Amazon! Какова вероятность такого!?!?\r\n\r\nНо ведь такой низкопробный лохотрон Amazon может легко обнаружить, предотвратить и убрать!\r\n\r\nА вот есть я — человек, который пытается оставить честный критический отзыв. В 2018 году у меня было 32 заказа (часто из нескольких предметов). 41 заказ в 2017 году. 56 заказов в 2016 году. История моего аккаунта восходит к 2006 году, когда я купил книгу Head First Java, 2nd Edition.\r\n\r\nНо моё мнение не разрешено публиковать на Amazon.\r\n\r\nПустая трата времени\r\nЯ бы не так не бесился, если бы это случилось впервые. Но за последний год я уже второй раз пытаюсь оставить неидеальный отзыв о товаре на Amazon и получаю ответ, что отзыв «не может быть размещён на веб-сайте в его нынешнем виде» после того, как я потратил полчаса на обзор (с фотографиями).\r\n\r\nВ декабре прошлого года я получил поврежденный товар Amazon Basics:\r\n\r\n\r\n\r\n\r\n\r\nА впоследствии пытался предупредить других потенциальных покупателей о своей проблеме:\r\n\r\n\r\n\r\nНо нет! Amazon его не пропустил!\r\n\r\nХотя после разговора с со службой поддержки мне дали скидку 30%, но я бы предпочел заплатить полную цену и вовремя получить неповреждённый товар, а не иметь дело с поддержкой, печатью марок на возврат, переупаковкой, поездкой к ящику для возврата или в отделение UPS, надеясь на получение более качественного товара.\r\n\r\nЯ подумал, что другие покупатели захотят узнать о проблеме. Но Amazon не позволяет их предупредить.\r\n\r\nВместо этого разрешает кучу поддельных отзывов в основном от ботов.",
            "images": [
                "https://habrastorage.org/getpro/habr/post_images/ee3/baf/3d1/ee3baf3d17648a2ad2fdbd286dcd7b09.jpg",
                "https://habrastorage.org/getpro/habr/post_images/1d8/1f5/751/1d81f5751ecd3adea03de2773e4e0d1d.jpg",
                "https://habrastorage.org/getpro/habr/post_images/04b/27c/d4e/04b27cd4e2b06bd24663c665f712db6e.jpg",
                "https://habrastorage.org/getpro/habr/post_images/30e/b84/a88/30eb84a883744a5bf9c28df0b39d6ae6.jpg",
                "https://habrastorage.org/getpro/habr/post_images/a26/45b/939/a2645b939fa5606c55080d11702e2fb2.jpg",
                "https://habrastorage.org/getpro/habr/post_images/103/797/2be/1037972bef5642ad35f2fe0d1a8d8039.jpg",
                "https://habrastorage.org/getpro/habr/post_images/b82/ed7/3b6/b82ed73b684944d230be72bd72fd8980.png"
            ]
        },
        {
            "title": "ReactOS теперь запускается с BTRFS раздела",
            "text": "Привет, Хабр! В этой серии мы продолжаем усиленно дружить драйвер WinBtrfs с ReactOS.\r\n\r\n\r\nА этот ваш Windows так умеет?\r\n\r\nНачнем по порядку. После предыдущего поста, был реализован мини-драйвер для загрузчика FreeLoader, позволяющий в read-only режиме читать файлы с раздела BTRFS. Здесь меня поджидала первая проблема — BTRFS это регистрозависимая файловая система. Здесь для поиска inode структуры (эта структура содержит базовую информацию о файле) в директории используется хеш имени файла, это позволяет ходить по путям без вытаскивания всех файлов, содержащихся в директории.\r\n\r\nОднако, в Windows мире такая вещь как регистр имени файла мало кого волнует, поэтому пути к драйверам, требующимся для загрузки ОС могут быть записаны в реестре в совершенно любом регистре.\r\n\r\nВ данный момент эта проблема решена старыми добрыми костылями — при запросе на поиск файла, System32 и SYSTEM32 заменяются на system32, то же самое с папкой drivers. Пока я думаю как можно было бы это сделать грамотно. Скорее всего буду каждый раз загружать полный список файлов в директории и делать регистронезависимый поиск — потери скорости на загрузчике особо видны не будут.\r\n\r\n\r\n\r\nЗагрузчик читает файлы, костыли закостылены — едем дальше.\r\n\r\nЯ разрабатывал код загрузчика в виртуальной машине Bochs, поскольку в ней такие вещи делать удобнее всего. Но она (как оказалось) имеет проблемы с запуском ReactOS, поэтому пришлось пересесть на привычный VirtualBox.\r\n\r\nИ тут меня ждала очередная засада — почему-то не работал загрузочный сектор. Как выяснилось, в реализации прерывания INT 13h AH=42h (расширенное чтение с диска) есть какие-то проблемы, из-за которых эта функция не может читать более 8 секторов за раз.\r\n\r\nИ вот, наконец, первое сообщение об ошибке (это даже не BSOD!)\r\n\r\n\r\n\r\nИсключение со STATUS_ACCESS_VIOLATION приходило из подсистемы WinSxS, которая в основном взята из Wine. Пару дней пришлось потратить на причину возникновения, поскольку через WinSxS проходит загрузка всех библиотек, а их при запуске много. В конце концов, выяснилось что проблема была не в WinSxS (фух), а в системном вызове NtQueryDirectoryFile.\r\n\r\nWinSxS часто использует эту функцию для поиска манифестов по маске (делая запросы типа таких: \"*_Microsoft.Windows.Common-Controls_6595b64144ccf1df_6.0.*.*_*_*.manifest\"), а в драйвере WinBtrfs закрался баг, связанный с обработкой масок, начинающихся на звездочку. Совсем простенький пулл-реквест можно посмотреть здесь.\r\n\r\nУдивительно, но этого было достаточно для того, чтобы пройти установку и загрузиться в рабочий стол\r\n\r\n\r\nВозможно, первая в мире загрузка с драйвера WinBtrfs. Первая реализация моего фикса тоже имела ошибки, из-за чего кое-где поехала графика и не загружались картинки.\r\n\r\nСобственно, система загружается, и даже работает (хотя стабильность не такая как в последнем релизе 0.4.9).\r\n\r\nНо проблем ещё полно:\r\n\r\n\r\nНет поддержки файла подкачки. Вообще говоря, на linux swap файлы на btrfs дисках тоже не поддерживаются, а патч висит уже несколько лет. Но WinBtrfs таки их поддерживает. У нас же несколько другая реализация менеджера памяти, чем в Windows, которая требует ещё одного системного вызова, отсутствующего пока в WinBtrfs.\r\nОшибки записи и переполнения памяти. Мне удалось зафиксировать парочку таких, например при установке клиента Git. Будем разбираться, где течет память\r\nBSODы при выключении и перезагрузке. Патч уже ждет одобрения\r\n\r\nДо конца GSoC осталось уже совсем чуть-чуть, в планах дальнейшее исправление багов, и решение проблемы с файлом подкачки (но это уже после окончания программы).\r\n\r\nНу а желающие поддержать разработку данной фичи, могут присоединиться к тестированию и разработке драйвера WinBtrfs.",
            "images": [
                "https://habrastorage.org/webt/is/zl/yu/iszlyufhm-cbubmu-loymwhvq2i.png",
                "https://habrastorage.org/webt/29/da/yb/29daybb7cweex3nccthfhwmqdc0.png",
                "https://habrastorage.org/webt/ui/ai/fg/uiaifg7-3jpkjoebdkxct-uu4qm.png",
                "https://habrastorage.org/webt/9f/kn/yg/9fknyg3c0tyshqoitbpukzmildo.png"
            ]
        },
        {
            "title": "Аудиогаджет специального назначения: ценная “вещь” для посольства США",
            "text": "Возможно, кто-то понял о чем пойдет речь из заголовка, для прочих поясню — этот пост посвящен эндовибратору Льва Термена, который также именуют “Златоуст” и “The Thing” (“вещь”, “нечто”). С этим устройством связан беспрецедентный случай в истории мировых разведок, когда посольство США в Москве безнаказанно прослушивалось на протяжении семи лет. При этом у американских служб технической безопасности не было возможности обнаружить “жучок”, так как последний не имел источника питания и представлял собой небольшую конструкцию из металла.\r\n\r\n\r\n\r\n\r\nРазработка гениального заключенного\r\nКак я уже отмечал, эндовибратор был впервые создан гениальным русским изобретателем Львом Терменом. Отец “вещи” был широко известен как один из изобретателей электронной музыки и первого электромузыкального инструмента Терменвокса, создатель одной из первых версий электромеханического телевизора и других передовых для своего времени устройств.\r\n\r\n\r\n\r\nС 1925-го по 1938-й годы Лев Термен безбедно жил в США. Вернувшись в Союз, он был арестован в 1939 году по обвинению в громком “покушении” на Кирова и участии в т.н. “пулковском” заговоре. “Гуманное решение” Особого Совещания при НКВД СССР отправило изобретателя искупать несуществующую вину перед Родиной на Колыму, назначив восьмилетний срок лишения свободы. \r\n\r\nУже через год в ведомстве Лаврентия Берии одумались и перевели ученого отбывать наказание в одну из Московских шарашек (ОКБ — “особые конструкторские бюро” или попросту НИИ тюремного типа, для ученых и инженеров, с улучшенными по сравнению с лагерями условиями, где традиционный для советской пенитенциарной системы физический труд заменялся интеллектуальным).\r\n\r\n\r\nНИИ-1 или по иному «кучинская шарага»\r\n\r\nВ 1943-м году Лев Термен продолжал отбывать срок в кучинской шараге, где получает задачу разработать устройство, которое будет сложно обнаружить такими методами как нелинейный локатор и индикатор поля, наиболее распространенные средства для обнаружения радиозакладок.\r\n\r\nПринцип действия\r\nУчитывая, что методы обнаружения, используемые в то время, предполагали поиск активного источника электромагнитного поля, Термен пришел к выводу о том, что необходимо создавать пассивное устройство, которое будет выполнять функцию своеобразного радиозеркала. \r\n\r\nИтогом работы стало устройство, известных аналогов которого на тот момент не существовало. Принцип работы “Златоуста” (как его назовут впоследствии) был следующим: для активации устройства на него направлялся мощный ультравысокочастотный (800 МГц) радиосигнал. Мембрана, установленная в устройстве, резонировала от звуковых волн и затем модулировала отражаемый сигнал, который улавливался специальным приёмнком, записывался на магнитную проволоку или стенографировался.\r\n\r\n\r\n\r\nУстройство не имело встроенных источников питания и было сравнительно небольшим. Конструкция была предельно проста — металлическая полость с резонирующей мембраной и объемом около 2-х кубических сантиметров, а также антенна длиной около 30 см.\r\n\r\nОсобого внимания заслуживает приемник, за характерный внешний вид названный “Лось”. Созданный коллективом той же шарашки, он был способен принять и обработать отраженный от эндовибратора модулированный сигнал так, чтобы можно было слышать и записывать отчетливую речь.\r\n\r\n\r\n\r\nТроянский герб от советских пионеров\r\nПосле того как устройство было разработано, дело оставалось за его размещением. Целью стало посольство США, которое было одной из самых желанных целей оперативно-технических служб НКВД, НКГБ, МГБ и иных советских спецведомств. \r\n\r\nВозможность представилась 9 февраля 1945 года, на эту дату была назначена церемония открытия второй очереди пионерского лагеря «Артек». В образцово-показательное место отдыха советских детей пригласили большую тройку (Сталина, Рузвельта и Черчилля), но руководители коалиции не нашли время для посещения и направили на мероприятие своих послов.\r\n\r\n\r\nГарриман в компании Сталина. Посол часто общался с вождем, не удивительно, что в ведомстве Берии много знали о его пристрастиях\r\n\r\nНа этом мероприятии послу США Гарриману решили вручить герб США, который был выполнен из ценных пород дерева. В гербе предварительно установили эндовибратор, а также сделали замаскированные отверстия для звука, которые размещались в ноздрях у орла.\r\n\r\nДело в том, что Гарриман был неравнодушен к разного рода поделкам из редких и ценных пород древесины, для “троянского” подарка таких пород применили сразу двадцать. По данным Владимира Алексенко, отставного подполковника оперативно-технической службы ПГУ КГБ, инициатива сделать Гарриману такой “подарок” принадлежала лично Лаврентию Берии.\r\n\r\n\r\nОригинал — большой печати США, подаренной Гарриману. Музей ЦРУ\r\n\r\nПодарок от Берии от пионеров пришелся послу по вкусу. После вручения он с трудом сдерживал восхищение презентом и уже начал думать от том, где разместить ценный экспонат для его коллекции. \r\n\r\nПо воспоминаниям очевидцев, Гарриман задал вопрос: «Куда я могу повесить это чудо?». На него моментально среагировал советский дипломат Валентин Бережков, который шепотом порекомендовал повесить герб в кабинете, чтобы вызвать зависть британских коллег. Подарок и рекомендация сработали, Гарриман распорядился повесить герб в его кабинете.\r\n\r\nКак “Вещь” работала в посольстве\r\nДля обеспечения работы устройства было создано два секретных поста, располагавшихся в непосредственной близости к зданию посольства США. На одном посту находился мощный излучатель радиоволн, работавший на частоте 800 МГц, на другом дежурили сотрудники с приёмником “Лось” и магнитофонами. \r\n\r\n\r\n\r\nВ нужный момент включался передатчик и сотрудники на принимающем посту могли отчетливо слышать и записывать переговоры в кабинете посла. Таким образом чекисты прослушивали кабинет посла на протяжении семи лет. После Гарримана до момента обнаружения устройства в кабинете с уникальным гербом работало еще трое послов США.\r\n\r\nОбнаружение\r\nСуществует несколько версий обнаружения устройства. Сотрудники отечественных спецслужб утверждают, что причиной раскрытия одного из самых эффективных жучков в истории стало предательство. По версии посольства США, “Златоуст” нашли доблестные сотрудники технических служб британской разведки.\r\n\r\nИтак, по первой версии на мысль о “жучке” западных партнеров навел перебежчик из ГРУ Петр Попов, который рассказал, что в посольстве США существует серьезная утечка информации. Событие произошло в 1952-м году. \r\n\r\nВторая версия гласит, что в 1951-м сканируя эфир, технические специалисты британского посольства (находится рядом с посольством США, около 700 метров) случайно услышали английскую речь и сообщили заокеанским коллегам. \r\n\r\nОднако известно, что вызванный по этому поводу американский специалист \r\nДон Бэйли не смог обнаружить никаких устройств, подозревая, что чекисты успели выключить прибор. Так или иначе “вещь” была извлечена из герба только в 1952-м году, когда при смене посла все предметы в посольстве подвергались тщательной проверке.\r\n\r\n\r\nДемонстрация «вещи» в ООН\r\n\r\nДанные об обнаружении устройства американские дипломаты придали огласке только в 1960-м году. Они использовали демонстрацию герба в ООН в качестве ответа на обвинения в шпионаже со стороны США, озвученные советской стороной после задержания пилота U-2, Пауэрса.\r\n\r\n\r\n\r\nЗагадка в неисправности\r\nСвоему названию в западных источниках эндовибратор обязан недоумению специалистов, которые осматривали его в США. Интересно, что инженеры ЦРУ долго не могли понять, что именно попало им в руки и как оно работает. Проблем добавляло и то, что те, кто извлекал устройство из герба случайно повредили тонкую мембрану — это ещё больше запутало специалистов.\r\n\r\n\r\nПитер Райт и его схема работы «вещи»\r\n\r\nНа принцип работы устройства смогли пролить свет только сотрудники МИ-5, а если конкретно, инженер Питер Райт, который по совместительству был ведущим радиоинженером компании Marconi. Он первый из западных специалистов понял, что имеет место повреждение мембраны. Райт описал принцип работы устройства и назвал его «объемным пассивным резонатором». \r\n\r\nИтог\r\nСозданный в психологически тяжелых условиях заключения (кормили в шарашках сносно) уникальный прибор Термена, стал доказательством победы изобретательности над обстоятельствами. Завершив работу над “вещью”, физик был переведен в Туполевскую шарашку (ЦКБ-29), где разработал инфракрасный микрофон “Буран”. Вскоре его выпустили, наградив т.н. “закрытой” Сталинской премией. Подробнее о жизни Льва Термена можно узнать здесь. \r\n\r\nИдея русского инженера была многократно скопирована, с 50-х подобные устройства появились у американских и британских спецслужб. Эндовибраторы и приборы работающие на аналогичных принципах до сих пор пользуются популярностью у спецслужб, как незаметное устройство для прослушивания.\r\n\r\nИспользованы фотоматериалы:\r\n3dnews.ru\r\nwww.popmech.ru\r\njewish.ru\r\ntopwar.ru\r\nmaxpark.com\r\nback-in-ussr.com\r\n\r\nДжинса\r\nВ нашем каталоге нет спецтехники, но есть УМЗЧ, акустические системы, ЦАП, наушники и прочая аудиоаппаратура высокой верности воспроизведения.",
            "images": [
                "https://habrastorage.org/webt/vo/kp/hv/vokphv0axfzuqhlmvukoadilo8i.jpeg",
                "https://habrastorage.org/webt/xc/w0/ts/xcw0tsgscib-gxkgd4hqyczkjea.jpeg",
                "https://habrastorage.org/webt/zr/yb/rd/zrybrdwv57pc3e7u5dqvuhcth9y.jpeg",
                "https://habrastorage.org/webt/wh/gj/_k/whgj_kjgpthouljxqd3iikox6ii.jpeg",
                "https://habrastorage.org/webt/y8/un/vd/y8unvdwstomxq_ut4vinx4pg4gw.jpeg",
                "https://habrastorage.org/webt/po/gq/uk/pogqukuuzv0rqvvxvlslqdl5mjm.jpeg",
                "https://habrastorage.org/webt/ln/fk/wl/lnfkwlm2kiqfno0-goe6tkhrz9i.jpeg",
                "https://habrastorage.org/webt/9u/pz/0r/9upz0r9_zurqbov6ldokcdtxzvc.jpeg",
                "https://habrastorage.org/webt/4p/wg/tz/4pwgtz3blubaxsjeqeyio8eaje0.jpeg",
                "https://habrastorage.org/webt/zl/tk/qq/zltkqqpz_toc08xijdeozdtfeaq.jpeg"
            ]
        },
        {
            "title": "Как научить Zabbix отправлять уведомления о проблемах прямо на рабочий стол",
            "text": "\r\nКартинка: источник\r\n\r\nПривет, Хабр! Меня зовут Илья Аблеев, я работаю в отделе мониторинга Badoo. \r\n\r\nМожно долго холиварить на тему того, какая система мониторинга круче. Основным инструментом для реакции на проблемы в Badoo является Zabbix, и мы неоднократно делились опытом его кастомизации. \r\n\r\n«Из коробки» узнавать о новых проблемах можно либо через веб-интерфейс, либо по почте/SMS. Это хорошо работает и до определённого момента нас устраивали эти способы.\r\n\r\nНа сегодняшний день в нашей системе несколько инстансов сервера, тысячи хостов, сотни тысяч проверок и примерно столько же триггеров, на которые нужно как можно более оперативно реагировать. После ряда инцидентов, когда только на обнаружение проблемы мы тратили до десяти минут (что совершенно недопустимо), мы осознали, что нам жизненно необходимы другие способы уведомления о проблемах. Тогда, возможно, наша реакция была бы быстрее.\r\n\r\nОптимальным решением, на наш взгляд, был бы вывод важных уведомлений поверх всех окон (браузеров, чатов, консолей). В этой статье речь пойдёт о том, как мы допилили Zabbix, научив отправлять их прямо на рабочий стол.\r\n\r\nКому подойдёт данное решение:\r\n\r\n\r\n дежурным администраторам, которые не только круглосуточно смотрят в монитор, но и занимаются решением других задач;\r\n всем остальным администраторам, которым не нравится просматривать простыню PROBLEM и OK`ов в почте или SMS, но которые хотят своевременно узнавать о критичных проблемах.\r\n\r\nПридётся потратить время на установку, но, думаю, если вы используете Zabbix и уже использовали кастомные скрипты, для вас это не составит труда.\r\n\r\nВнимание! Получение уведомлений данным способом вызывает привыкание, долговременное его использование создаёт впечатление, что он является неотъемлемой частью Zabbix.\r\n\r\nРасскажу по шагам, что и как мы делали. Техническая реализация достаточно проста:\r\n\r\n\r\nZabbix отправляет алерт на какое-то событие.\r\nСкрипт-отправщик на сервере отправляет данные клиенту на десктоп по UDP.\r\nСкрипт-получатель принимает уведомление, и инициирует появление всплывающего сообщения посредством дополнительного приложения.\r\n\r\nТретий пункт может отличаться в зависимости от того, какую операционную систему вы используете и какое приложение вам больше нравится. \r\n\r\nШаг первый: настройка Zabbix\r\nВ официальной документации подробно рассказано, как создать свои алерты. \r\n\r\nКод проекта доступен на GitHub: https://github.com/ableev/ZbxDsktp. \r\n\r\n\r\nЗаранее положим zbxpush.py в AlertScriptsPath на Zabbix-сервер.\r\n\r\nДалее в веб-интерфейсе: Administration → Media types → Create. \r\n\r\n\r\n\r\n\r\n\r\n3. Заранее пропишем IP/FQDN, на который мы будем отправлять алерты.\r\n\r\nДанный пункт можно модернизироватьНапример, у нас сделано так: существует главный сервер мониторинга, при SSH-логине скрипт запоминает IP зашедшего и начинает отправлять на него алерты. Таким образом, чтобы активировать получение данных у себя, не нужно каждый раз менять экшен. \r\n\r\nВ веб-интерфейсе: Administration → Users → %username% → Media.\r\n\r\n\r\n\r\n4. Создадим действие на триггеры.\r\n\r\nВ веб-интерфейсе: Configuration → Actions.\r\n\r\n\r\n\r\nФормат отправки\r\n{TRIGGER.NSEVERITY}@@@{HOST.NAME}@@@{TRIGGER.NAME}\r\n\r\nПервое — числовой формат триггера (4 или 5 — влияет на отображаемую иконку: High или Disaster), второе — заголовок уведомления, третье — тело сообщения. \r\n\r\n@@@ — чтобы было удобно разбивать на столбцы, ибо в названиях триггеров может быть написано что угодно (по крайней мере, у нас :)), но точно не эта комбинация.\r\n\r\n\r\n\r\n\r\n\r\nШаг второй: сервер отправляет данные клиенту \r\nЛогика простая: получаем событие, пересылаем его клиенту. \r\n\r\nzbxpush.py\r\n\r\nЗдесь вы можете изменить UDP на TCP. Мы выбрали UDP по одной простой причине: Zabbix отправляет все уведомления последовательно, а значит, если ваш компьютер будет недоступен, в случае использования TCP уведомления будут отправляться с большой задержкой. \r\n\r\nНо ведь UDP – это ненадёжно Читатель, до которого доходит шутка про UDP, заметит, что в случае отправки алертов по UDP появляется вероятность потерять их где-нибудь между сервером и десктопом. И будет прав. Но суть не в том, чтобы гарантированно доставить сообщение, а в том, чтобы просто и быстро привлечь внимание к дашборду с проблемами: «Эй, там что-то случилось, пойди и посмотри». \r\n\r\nНе забудьте сделать скрипт исполняемым!\r\n\r\nШаг третий: получаем событие и отображаем уведомления\r\nzbxlistenerd.py – скрипт, который будет крутиться в фоне и запускать уведомления\r\n\r\nsettings.cfg — файл с настройками клиента\r\n\r\nicons/5.png, icons/4.png — иконки для разных критичностей триггеров\r\nДальше наши пути расходятся. «Клиентская» часть предполагает немного творчества, так как каждый создаёт окружение для себя. \r\n\r\nЧто бывает необходимо:\r\n\r\n\r\nиконки, соответствующие критичностям триггеров;\r\nзвуковое сопровождение всплывающих уведомлений;\r\nвыполнение действия по нажатию на уведомление (SSH-логин, открытие ссылки, заведение тикета о проблеме и т. д.).\r\n\r\nВ нашей компании в качестве десктопной ОС в основном используются Linux и Mac OS, поэтому рассмотрим несколько примеров для них. Если же вы реализуете то же самое для Windows, добро пожаловать в комменты! С радостью дополним пост. \r\n\r\nLinux\r\n\r\n\r\nПриведу пример, который довелось использовать: notify-send в Xfce (на скриншоте выше). Почему notify-send, а не тот же Python с использованием libnotify? Да потому что он есть во всех популярных десктоп-дистрибутивах (Ubuntu, Fedora, SUSE) и работает со всеми (по крайней мере популярными) DE (Gnome, KDE, Xfce).\r\n\r\nСовет: если у вас случаются периоды массовой недоступности чего-либо (например, отвалился свитч — и вы завалены горой триггеров о недоступности серверов), сразу настройте хоткей на завершение процесса notify-send. \r\n\r\nMac OS\r\nПоскольку изначально решение реализовывалось на базе бесплатного приложения, а затем мы опробовали платное, примеров будет два.\r\n\r\nterminal-notifier\r\n\r\n\r\nПосле недолгого поиска был выбран бесплатный terminal-notifier.\r\n\r\nПлюсы: \r\n\r\n\r\n можно устанавливать разные иконки для разных критичностей;\r\n можно формировать ссылки на графики в Zabbix и открывать их по клику на уведомление;\r\n можно реализовать открытие SSH-ссылок: увидели нотификацию -> кликнули -> сразу зашли на хост.\r\n\r\nМинусы: отсутствуют (особенно после того, как была добавлена поддержка иконок).\r\n\r\nGrowl\r\n\r\nДля включения установите growl_enabled = True в settings.cfg.\r\n\r\nВо времена, когда terminal-notifier не умел использовать кастомные иконки, Growl вполне с этим справлялся. Поэтому наше любопытство победило жадность — и мы опробовали это довольно популярное приложение (которое, надо сказать, умеет не только иконки менять — это целый центр уведомлений). \r\n\r\nПлюсы:\r\n\r\n\r\n возможно, у вас приложение уже установлено; \r\n можно выбрать разные иконки под разные критичности;\r\n так же, как и в terminal-notifier, можно настроить действия по нажатию на уведомления.\r\n\r\nМинус: платное.\r\n\r\nЕсли же Growl у вас нет, рекомендую всё же воспользоваться terminal-notifier.\r\n\r\nЗаключение \r\nВот так, с помощью нехитрых приспособлений… \r\n\r\nЧто мы получили в итоге:\r\n\r\n\r\nбыстрая доставка уведомлений админам;\r\n\r\nуменьшение времени реакции на события (от момента «узнали» до «починили» или «передали дальше»);\r\n\r\nвозможность совершать простые полуавтоматические действия:\r\n\r\n\r\nДалее всё зависит от вашего творческого потенциала. \r\n\r\nКогда-то давно, когда я работал в компании-провайдере, при падении интернет-канала из всех колонок и наушников на рабочем месте доносился звук сирены. Это приводило дежурного (меня) в ступор, не давало адекватно сообщить о проблеме по телефону, но он (я) старался как можно быстрее эту проблему решить. \r\n\r\nЛично мне уже известны случаи прикручивания к скрипту звука свиньи из популярного антивируса и говорилки из популярного переводчика. :) \r\n\r\nПри наличии свободного времени, желания и современных технологий можно сделать так\r\n\r\nБыстрых вам реакций на инциденты!",
            "images": [
                "https://habrastorage.org/webt/98/ev/mt/98evmtwknc1eykixoq9zx5yrcke.gif",
                "https://habrastorage.org/webt/n5/n6/55/n5n655i9syco1oxqdbhuxsqokja.png",
                "https://habrastorage.org/webt/ht/mb/pi/htmbpi7wht4kh1erwsepplynyto.png",
                "https://habrastorage.org/webt/nt/nb/um/ntnbumq93_itlvuuhwjquf1wgza.png",
                "https://habrastorage.org/webt/sh/sx/7t/shsx7tx8a-0nfqyene9cbdehnqe.png",
                "https://habrastorage.org/webt/id/4i/tl/id4itli-nikquvuvg1m3umml4bm.png",
                "https://habrastorage.org/webt/zv/b6/zo/zvb6zo6amctuxok6gka-f7j7sws.png",
                "https://habrastorage.org/webt/4k/5l/zo/4k5lzo4vfc5xo4vwbfekifltsj0.png",
                "https://habrastorage.org/webt/er/yd/cv/erydcvz1e6xp60fun_guorprhuo.png"
            ]
        },
        {
            "title": "Как я полетал по всей стране, внедряя проект на несколько тысяч рабочих мест",
            "text": "\r\n Самая большая голова Ленина в мире. Площадь Советов в Улан-Удэ\r\n \r\nКогда ты берёшься за проект длиной два года с географией по всей стране, то ждёшь, проблем с согласованием, странных отношений с контрагентами, грузчиков с серверами в руках, непредоставленных портов по ТЗ и много другого. К этому меня жизнь готовила: всё это прекрасно описано в методологии подготовки проект-менеджеров. \r\n\r\nВсё было не зря.\r\n\r\nТакие истории очень хорошо рассказывать через пару лет в курилке, но не встречать на проектах.\r\n\r\nЧто надо было сделать\r\nОсенью 2016 года одна крупная организация окончательно решила перейти на рабочих местах на VDI-доступ. Их прикладное ПО менялось, а компьютеры — нет. Поэтому в будущем это всё начало бы неминуемо тормозить. Прикинув стоимость обновления парка ПК, решили сразу сделать следующий шаг. И пошли на VDI. \r\n\r\nВ 2017 году мы закончили 5 тысяч рабочих мест в нескольких регионах. \r\n\r\nАрхитектура решения была задана в момент конкурса. Она следующая:\r\n \r\n\r\nКак видите, тут 5 серверных узлов (это размещение в дата-центрах и на отдельных площадках), по одному для группы регионов. Между собой эти пять площадок связаны по VPN через корпоративную сеть организации (есть некий узел с продакшн-серверами баз данных в центре). Внизу схемы — типы рабочих мест.\r\n\r\nСофт:\r\n\r\n\r\n \r\nЯдро — гиперконвергентная архитектура с VSan, VMWare — гипервизор до 7 версии. Одиннадцать серверов: по 3 сервера управления, 8 compute, коммутаторы. Физически это одна стойка: криптосредства, сеть управления, контроллеры, vSAN, продакшн. Каждая стойка может удерживать до 5 тысяч пользователей. В планах на следующий год — удвоение. \r\n\r\nУдалённое сопровождение в контракте, но ездить надо ногами: не удаётся согласовать с безопасниками ряд вещей. Мы держим пять сотрудников, которые занимаются сопровождением из центра. Плюс у нас есть субподряды во всех регионах, чтобы прийти, заменить железку. ЗИП не храним, всё задублировано. У производителей железа покупаем на следующий рабочий день, ЗИП хранят вендоры. \r\n\r\nНа конечных рабочих местах с точки зрения пользователя мы не трогаем ничего, кроме того, что кладём ещё одну иконку на рабочий стол. С неё они подключаются. В какой-то момент их администраторы решат, что хватит обновлять ПО на локальных дисках и, когда пользователи попривыкнут, оставят только эту иконку. \r\n\r\nНачало\r\nНа начало работ мы знали, что организации довольно дорого класть собственную оптику (что логично), поэтому она покупает каналы у магистральных провайдеров. В большинстве случаев это не проблема, но на Камчатке, например, у них спутниковый гейт. Это создаёт определённые сюрпризы для VDI. Забегая чуть вперёд — туда проект пока не распространили, но в ряде городов нам достались очень узкие каналы. \r\n\r\nВ отношении работы с приложением пользователи довольно нетребовательные к полосе — там статичные экраны, и двигается только курсор. Однако они довольно часто отправляют сканы документов, например, паспортов для профиля клиента. Это создаёт дополнительную нагрузку на канал.\r\n\r\nТри базовые площадки — это их собственные серверные узлы в их собственных офисах в центре городов. Ещё две — это внешние дата-центры, где сделаны загородки под эту компанию. \r\n\r\nТиповые сложности\r\nПервый этап — обследование. Ездишь по точкам и смотришь глазами, где что будет стоять. Прикидываешь, как и чего: общаешься с местными айтишниками, проверяешь правила работ на площадках, смотришь, куда складывать коробки, кто чего будет поднимать на 4 этаж, нужны ли грузчики, как с пропусками для них. Ездили вдвоём: я, ПМ для организации, и архитектор (он же техруководитель проекта). Кое-где понадобились дополнительные маршрутизаторы. На двух площадках не было нужных провайдеров, заказчик пошёл договариваться с ними, чтобы они протянули туда линк. \r\n\r\nНужно было решать вышеописанную проблему с загрузкой канала сканами. Происходит вот что: весь поток со сканера отправляется на серверный узел, а уже там происходит обработка. Фактически же надо было делать предобработку в конечных подсетях ещё до ухода в корпоративную сеть. Есть регламент по сканированию, чтобы документ был различим. Есть средства VMware — мы привлекли их экспертов для оптимизаций, тестирования и ускорения. Они пошаманили, сделали преднастройки и вынесли вердикт: сделать быстрее, чем получилось, можно только расширением каналов.\r\n\r\nТакая же работа была по печати. \r\n\r\nБыли проблемы с драйверами старых моделей МФУ. Каждый типовой образ делался совместно с людьми из региона. В каждом регионе нас сопровождала своя команда. Мы выдавали тестовый образ, они набивали дровами, ПО, тестировали, что всё это работает, дальше в боевой пул. Для каждого из регионов на рабочие места был создан свой базовый образ. Они отличаются набором драйверов для принтеров-сканеров и немного софтом. Пользователи одного региона работают с одним образом. Человек подключается и с этой виртуальной машины и ходит к своим приложениям. В «чужие» регионы пользователи не ходят. \r\n\r\nОсновные сложности, которые возникли при настройке VDI. Безопасники нам очень долго и упорно не хотели согласовывать в принципе подключение. Причина проста: текущая нормативная база по учёту подписей отстаёт от реальности. Нам пришлось разъяснять, переделывать и согласовывать бизнес-процессы. То есть мы взяли и начали писать их же регламенты работы.\r\n\r\nПосле обследования и составления образов надо было просто поездить и расставить оборудование. Мы знали, что нас ждут сюрпризы.\r\n\r\nНетипичные проблемы\r\nИтак, столица одного из сибирских регионов… вот ЦОД, вот ваше стойко-место. Всё готово, за исключением того, что внутри загородки нет питания. Люди, которые отвечают за ЦОД, нас уверяли, что для того, чтобы сделать розетку внутри загородки, надо выключить весь дата-центр. Надо согласовывать с налоговой и прочими товарищами, чтобы в этот день не было зарплат, налогов и вообще ничего критичного. Лучше это делать за полгода. \r\n\r\nМы занялись планированием. Попутно нашли подрядчика, который строил этот ЦОД. Вообще, для меня очень странно, что точки питания сразу не сделали, одна стоит до 5 тысяч рублей с автоматами. Помещение сделано хорошо, всё на Шнайдере. Оказалось, технологические розетки APC поставляются под заказ, потому что мало кому они нужны. Срок заказа 11–14 недель. Их нет НИГДЕ. Но нас, как в том анекдоте, спасло русское раздолбайство: в какой-то момент подрядчик подобрел и вспомнил, что у них в закромах есть одна неучтённая. И ЦОД отключать было не надо. В этом году ещё раз расширяемся, опять розетки не будет — заказчик обещал принять решение, оставаться на площадке или менять её за 2 недели до пуска оборудования.\r\n\r\nА вот что было в городе-миллионнике — промышленный ЦОД, позиционирующий себя как очень крутой. Там вообще некуда выкинуть мусор было в прошлом году. Коробка от сервера осталась — сами вывозите. А ты в командировке. Заказываешь контейнер, вывозишь. Хорошо хоть мы, наученные горьким опытом, имеем наличные под аванс на случай ЧП. На месте получается всё сделать быстро, но с бухгалтерией потом закрывать все эти затраты — целое приключение. Попробуй обоснуй заказ на вывоз мусоровоза в командировочных расходах. До этого была проблема несколько лет назад: на обслуживание кондиционеров заказывали автовышки. Та же беда.\r\n\r\nВечерние вылеты. В 4 утра по Москве старт, перелёт через всю страну, в 8 утра прилетел и сразу едешь на совещание, тебя встречает заказчик. Оттуда на объект. И вот так пошёл второй рабочий день сразу за первым. А давайте то посмотрим, а давайте это — ты вроде не можешь отказаться. Нужно планировать дополнительный день всегда при таких перелётах.\r\n\r\nК москвичам, которые приезжают тебе всё настраивать, относятся двояко. С одной стороны — не до конца доверяют, потому что чужой человек. С другой стороны, очень активно хотят помочь, потому что знают, что работы идут в разных регионах. Поэтому всё то, что можно решить на месте — решают. И ещё стараются показать город. Пока никого не знаешь — настороженно-благожелательное отношение. Ещё для них такие проекты — небольшой праздник, потому что айтишники могут просить что-то в федеральном центре. Все закупки у них централизованные: пишут обоснование в центр, а там закупают. Под наш проект прошли все обоснования «сделайте пошире и потолще Инет», «сделайте больше серверное помещение» и так далее.\r\n\r\n \r\n\r\nОчень много было работ по коммуникации между их отделами. Со стороны заказчика в проекте участвовало много подразделений и департаментов, они все независимы. Каждый из смежных департаментов будет работать только по внутренним распоряжениям несмотря на всю вот эту пилотность проекта. Ты должен, несмотря на то, что они не общаются или плохо общаются — общаться со всеми, знакомиться, надоедать, писать. В итоге получается, что заниматься внутренней организацией их работы. В паре городов мы писали за них письма, который они пересылали уже другим людям внутри организации.",
            "images": [
                "https://habrastorage.org/webt/jy/ed/ah/jyedahczdolywztub2clr-7oxbe.jpeg",
                "https://habrastorage.org/webt/ka/oz/tp/kaoztp9l70oplisogovn9vu5yde.jpeg",
                "https://habrastorage.org/webt/y7/ud/zi/y7udzitwyp667ezcuxh-v2h7-pw.jpeg",
                "https://habrastorage.org/webt/mo/xm/ho/moxmhogz6d5v4p-5zs2cpsxtk8k.jpeg"
            ]
        },
        {
            "title": "Зачем я рипнул один компакт-диск 300 раз",
            "text": "Я коллекционирую музыку: покупаю компакт-диски, оцифровываю их программой Exact Audio Copy, сканирую обложки и вкладыши. Иногда это непросто, если CD издан ограниченным тиражом за рубежом 10 лет назад. Сложнее всего, если на компакте производственный дефект — и некоторые треки не читаются.\r\n\r\nАльбом аранжировок для фортепиано 帰るべき城 от Altneuland вышел в 2005 году. Я нашёл его спустя три года (вероятно, на YouTube), скачал лучшую копию — и внёс диск в список будущих покупок. Последние достижения в технологиях международной почты позволили в прошлом году купить бэушный диск. К сожалению, ни один из моих CD-приводов не смог прочитать трек № 3. Такое часто бывает при покупке старых дисков, особенно когда они прошли через центр международной доставки USPS. Я отложил его и начал искать другой экземпляр, который нашёл в прошлом месяце. Он прибыл в пятницу — и я сразу же попытался его рипнуть. Но с толкнулся с точно такой же ошибкой. Похоже, тут дело не в износе или повреждении — вероятно, диск вышел дефективным прямо с завода.\r\n\r\nДОПОЛНЕНИЕ: После проведённого расследования я больше не считаю, что это заводской дефект. Когда я записываю начало или конец сбойной дорожки на пустой CD-R и копирую его, то риппер выдаёт ту же ошибку! Попробуйте сами с файлом minimal.flac.\r\n\r\nОсталось два варианта: или попытаться когда-нибудь найти другую копию, которая будет успешно копироваться (маловероятно), или каким-то образом восстановить исходные звуковые данные c повреждённых дисков. Вы уже знаете, какой вариант я выбрал.\r\n\r\nКак работает риппер\r\n\r\nEAC не смог прочитать трек № 3 с диска [帰るべき城] \r\n\r\nCD хранят цифровые данные, но между дисками, лазерами и оптическими диодами вполне аналоговый интерфейс. Ошибки чтения возникают по разным причинам: грязный носитель, царапины на защитном слое поликарбоната, вибрации самого привода. Примитивные коды коррекции ошибок в стандарте CDDA помогают минимизировать звуковые искажения на редко используемых дисках, но не способны полностью восстановить битовый поток на CD с большим количеством ошибок. Современные рипперы решают проблему с помощью двух важных методов обнаружения ошибок: избыточного чтения и AccurateRip.\r\n\r\nНа странице EAC: Extraction Technology описано, как EAC производит избыточное чтение:\r\n\r\nВ безопасном режиме программа считывает каждый сектор минимум дважды [...] Если возникает ошибка (чтения или синхронизации), то программа продолжает считывать этот сектор до тех пор, пока 8 из 16 попыток не окажутся идентичными. Такая процедура проводится максимум один, три или пять раз (в соответствии с выбранным качеством восстановления ошибок). Так что в самом худшем случае плохие сектора считываются 82 раза!\r\nВсё просто. Если запрос на чтение иногда возвращает неверные данные, прочитайте его ещё раз, а затем будьте особенно осторожны, если первые два чтения дают разный результат. AccurateRip использует тот же принцип, но распределённо: в этот сервис рипперы отправляют контрольные суммы скопированных аудиофайлов. Идея в том, что если тысяча людей скопировали трек с одинаковыми битами, вероятно, это правильный рип.\r\n\r\nЭта статья о том, что делать, если оба метода не могут помочь. EAC не даёт результат, если каждое чтение возвращает разные данные, а в базе AccurateRip только одна запись о редком диске [1].\r\n\r\n«Я миновал десять тысяч проходов, десять тысяч проходов, чтобы увидеть вас»\r\n\r\nОптические приводы Asus, LG, Lite-On, Pioneer и неизвестного OEM \r\n\r\nЕсли CD не копируется, то логично использовать другой привод. Иногда конкретная модель более снисходительно относится к спецификациям CDDA или там лучшая прошивка для исправления ошибок, или что-то ещё. На форуме DBpoweramp есть рейтинг точности приводов CD/DVD, чтобы выбрать наиболее подходящий привод для рипа.\r\n\r\nВ субботу утром я купил пять новых CD-приводов разных производителей [2], попробовал их все — и нашёл тот, который смог держать синхронизацию на битом треке. К сожалению, подтверждение рипа не удалось получить — между всеми рипами выходило около 20 000 отличающихся байт.\r\n\r\nНо теперь у меня на диске были файлы .wav, а из этого можно извлечь пользу. Я рассудил, что ошибки чтения на плохом треке находятся где-то около «правильного». Поэтому есть смысл сделать несколько рипов и найти «консенсусное» значение для нестабильных байтов. Такой подход в итоге оказался успешным, но потребовал гораздо больше работы, чем я ожидал.\r\n\r\n«Количество переходит в качество»\r\nЯ начал с многократного копирования диска на одном из приводов, записи всех значений для каждого байта и объявления ошибки «исправимой», если более половины рипов выдаёт определённое байтовое значение для данной позиции. Начало было хорошим: количество неисправимых ошибок уменьшилось почти с ~6900 байт при N=4 до ~5000 байт при N=10. Выгода от каждого дополнительного рипа снижалась с течением времени, пока примерно на N=80 число неисправимых ошибок не стабилизировалось на уровне ~3700. Я прекратил рипы при N=100.\r\n\r\n\r\nИсправленные и неисправимые ошибки на количество rip \r\n\r\nЗатем я попытался 100 раз скопировать диск на втором приводе и использовать две карты коррекции, чтобы «заполнить» неисправимые позиции ошибок с первого привода. Но не получилось: на каждом приводе оказались тысячи исправлений, которые не соответствовали исправлениям на другом! Оказывается, нельзя устранить шум, совместив его с другим, но связанным источником шума.\r\n\r\n\r\nТо же самое, но для двух дисков с перекрёстной проверкой исправлений \r\n\r\nКустарное творчество\r\n\r\n\r\nНа сайте EAC есть ещё один хороший ресурс: тест качества DAE, который определяет качество прошивки привода по уровню исправляемых ошибок. Это более низкоуровневая обработка ошибок, когда привод исправляет ошибки чтения, а не просто сообщает о них. Загвоздка в том, что «безопасный режим» EAC доступен только при отключении этого встроенного кода коррекции ошибок, предполагая его неправильную работу.\r\n\r\nЯ подготовил тест путём прожига файла .wav на CD-R, выделив точный сектор на поверхности данных и осторожно закрасив его чёрным маркером. Вот это — гарантированные неустранимые ошибки по детерминированному шаблоне.\r\n\r\nЯ протестировал всех приводы и получил два интересных результата:\r\n\r\n\r\n\r\nПривод Lite-On я прежде использовал, чтобы обойти ошибки синхронизации. Он с удовольствием прожевал волшебный маркер, но его сильно смутили прямые линии на поверхности данных. Вы можете видеть, как вместо трёх раздельных пиков справа один гигантский сбойный блоб.\r\n\r\nErrors total Num : 206645159\r\nErrors (Loudness) Num : 965075 - Avg : -21.7 dB(A) - Max : -5.5 dB(A)\r\nError Muting Num : 154153 - Avg : 99.1 Samples - Max : 3584 Samples\r\nSkips Num : 103 - Avg : 417.3 Samples - Max : 2939 Samples\r\n\r\nTotal Test Result : 45.3 points (of 100.0 maximum) \r\n\r\n\r\n\r\nПривод Pioneer получил самый высокий балл по тесту DAE. На мой взгляд, график не выглядит каким-то особенным, но инструмент анализа сказал, что это лучшая прошивка для исправления ошибок в моём маленьком наборе.\r\n\r\nErrors total Num : 2331952\r\nErrors (Loudness) Num : 147286 - Avg : -77.2 dB(A) - Max : -13.2 dB(A)\r\nError Muting Num : 8468 - Avg : 1.5 Samples - Max : 273 Samples\r\nSkips Num : 50 - Avg : 6.5 Samples - Max : 30 Samples\r\n\r\nTotal Test Result : 62.7 points (of 100.0 maximum) \r\n\r\n«С определённого момента числа имеют значение»\r\nКак использовать прошивку Pioneer с хорошим исправлением ошибок, если «безопасный режим» EAC игнорирует её? Очень просто: переключите EAC в «пакетный режим» (burst mode) и записывайте на диск поток битов в том виде, в каком их сообщает прошивка. Как потом превратить эту кучу непроверенных файлов .wav в файл хорошего качества, как в «безопасном режиме»? Да тем же инструментом анализа ошибок, который мы использовали в рипах с Lite-On!\r\n\r\nПосле нескольких настроек конфигурации EAC и через сто рипов мы получаем такую красивую диаграмму. \r\n\r\n\r\nИсправленные и неисправимые ошибки на количество рипов (Pioneer)\r\n\r\nЧто можно отметить:\r\n\r\n\r\nНеисправимые битовые ошибки быстро стремятся к нулю, но никогда его не достигают.\r\nОгромный скачок исправленных ошибок в 53−54 рипах.\r\nКоличество ошибок до и после этого большого скачка практически не изменяется, что указывает на области стабильности в скопированных данных.\r\n\r\n0xA595BC09\r\nИспользуя почти идеальную коррекцию ошибок от Pioneer, я сгенерировал файл «лучшее предположение» и начал сравнивать его с рипами Pioneer. Как и ожидалось, обнаружилось несколько некачественных участков, которые я исправил, сделав ещё 10 рипов:\r\n\r\n$ for RIP_ID in $(seq -w 1 100); do echo -n \"rip$RIP_ID: \"; cmp -l analysis-out.wav rips-cd1-pioneer/rip${RIP_ID}/*.wav | wc -l ; done | sort -rgk2 | head -n 10\r\nrip054: 2865\r\nrip099: 974\r\nrip007: 533\r\nrip037: 452\r\nrip042: 438\r\nrip035: 404\r\nrip006: 392\r\nrip059: 381\r\nrip043: 327\r\nrip014: 323 \r\n\r\nЯ также нашёл что-то действительно интересное: несколько рипов выдавали абсолютно одинаковый контент! Помните, ведь это как раз критерий успеха в «безопасном режиме» EAC. Команда shncat -q -e | rhash --print=\"%C\" используется для вычисления контрольной суммы CRC32 необработанных аудиоданных: именно её применяет EAC.\r\n\r\n$ for wav in rips-cd1-pioneer/*/*.wav; do shncat \"$wav\" -q -e | rhash --printf=\"%C $wav\\n\" - ; done | sort -k1\r\n[...]\r\n9DD05FFF rips-cd1-pioneer/rip059/rip.wav\r\n9F8D1B53 rips-cd1-pioneer/rip072/rip.wav\r\nA2EA0283 rips-cd1-pioneer/rip082/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip021/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip022/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip023/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip024/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip025/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip026/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip027/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip028/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip030/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip031/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip040/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip055/rip.wav\r\nA595BC09 rips-cd1-pioneer/rip058/rip.wav\r\nAA3B5929 rips-cd1-pioneer/rip043/rip.wav\r\nABAAE784 rips-cd1-pioneer/rip033/rip.wav\r\n[...] \r\n\r\nТем временем повторные рипы некачественных участков позволили завершить анализ с нулём неисправимых ошибок. И когда я проверил этот файл, там был точно такой же аудиоконтент, как и в «обычном» рипе! Этого достаточно, чтобы объявить победу.\r\n\r\nЯ на 99% уверен, что успешно скопировал этот проблемный компакт-диск, а 0xA595BC09 является правильной CRC-суммой для трека № 3.\r\n\r\nПриложение A: compare.rs\r\nЭтот инструмент я использовал для вычисления вероятных ошибок байтов. Он не предназначен для долговременного использования, так что немного уродлив, но может быть интересен тем, кто наткнулся на эту страницу, решая такую же задачу.\r\n\r\nextern crate memmap;\n\nuse std::cmp;\nuse std::collections::HashMap;\nuse std::env;\nuse std::fs;\nuse std::sync;\nuse std::sync::mpsc;\nuse std::thread;\n\nuse memmap::Mmap;\n\nconst CHUNK_SIZE: usize = 1 << 20;\n\nfn suspect_positions(\n    mmaps: &HashMap<String, Mmap>,\n    start_idx: usize,\n    end_idx: usize,\n) -> Vec<usize> {\n    let mut positions = Vec::new();\n    for ii in start_idx..end_idx {\n        let mut first = true;\n        let mut byte: u8 = 0;\n        for (_file_name, file_content) in mmaps {\n            if first {\n                byte = file_content[ii];\n                first = false;\n            }\n            else if byte != file_content[ii] {\n                positions.push(ii);\n                break;\n            }\n        }\n    }\n    positions\n}\n\nfn main() {\n    let mut args: Vec<String> = env::args().collect();\n    args.remove(0);\n    let mut first = true;\n    let mut size: usize = 0;\n\n    let mut files: Vec<fs::File> = Vec::new();\n    let mut mmaps: HashMap<String, Mmap> = HashMap::new();\n    for filename in args {\n        let mut file = fs::File::open(&filename).unwrap();\n        files.push(file);\n        let mmap = unsafe { Mmap::map(files.last().unwrap()).unwrap() };\n        if first {\n            first = false;\n            size = mmap.len();\n        } else {\n            assert!(size == mmap.len());\n        }\n        mmaps.insert(filename, mmap);\n    }\n\n    let (suspects_tx, suspects_rx) = mpsc::channel();\n\n    let mut start_idx = 0;\n    let mmaps_ref = sync::Arc::new(mmaps);\n    loop {\n        let t_start_idx = start_idx;\n        let t_end_idx = cmp::min(start_idx + CHUNK_SIZE, size);\n        if start_idx == t_end_idx {\n            break;\n        }\n\n        let mmaps_ref = mmaps_ref.clone();\n            let suspects_tx = suspects_tx.clone();\n            thread::spawn(move || {\n                let suspects = suspect_positions(mmaps_ref.as_ref(), t_start_idx, t_end_idx);\n                suspects_tx.send(suspects).unwrap();\n            });\n        start_idx = t_end_idx;\n    }\n    drop(suspects_tx);\n\n    let mut suspects: Vec<usize> = Vec::with_capacity(size);\n    for mut suspects_chunk in suspects_rx {\n        suspects.append(&mut suspects_chunk);\n    }\n    suspects.sort();\n\n    println!(\"{{\\\"files\\\": [\");\n        let mut first_file = true;\n        for (file_name, file_content) in mmaps_ref.iter() {\n            let file_comma = if first_file { \"\" } else { \",\" };\n            first_file = false;\n            println!(\"{}{{\\\"name\\\": \\\"{}\\\", \\\"suspect_bytes\\\": [\", file_comma, file_name);\n            for (ii, position) in suspects.iter().enumerate() {\n                let comma = if ii == suspects.len() - 1 { \"\" } else { \",\" };\n                println!(\"[{}, {}]{}\", position, file_content[*position], comma);\n            }\n            println!(\"]}}\");\n        }\n    println!(\"]}}\");\n}\r\n1. В этой единственной записи AccurateRip к моему диску совпадают CRC для всех треков, кроме трека № 3: там указана сумма 0x84B9DD1A, а у меня 0xA595BC09. Подозреваю, что тот риппер не понял, что у него плохой диск. [вернуться]\r\n\r\n2. Очевидный вопрос при покупке CD- или DVD-привода в 2018 году: «Блин, а где ж их купить?». И мне нужен был не один, а несколько от разных брендов. Я знаю только один магазин поблизости, у которых в наличии есть DVD-приводы 5,25\". Только один магазин достаточно большой, чтобы не пожалеть место на полках на такие приводы, и достаточно странный, чтобы они не казались там неуместными. Конечно, я говорю о Frys Electronics. [вернуться]",
            "images": [
                "https://habrastorage.org/getpro/habr/post_images/6f5/e32/a86/6f5e32a86569ad14e42c0ea28a8de301.jpg",
                "https://habrastorage.org/getpro/habr/post_images/69e/9b0/ff6/69e9b0ff62e391da0701a6a4cd02b57d.png",
                "https://habrastorage.org/getpro/habr/post_images/44a/1ab/850/44a1ab850b96409640f45e9425f73652.jpg",
                "https://habrastorage.org/getpro/habr/post_images/b87/aaa/809/b87aaa809a043eaeaa2d049258fe0cb9.png",
                "https://habrastorage.org/getpro/habr/post_images/911/6d5/c33/9116d5c339461cb286edc4537c712a71.png",
                "https://habrastorage.org/getpro/habr/post_images/ec7/829/554/ec78295544b0a161b472598114e2be2d.jpg",
                "https://habrastorage.org/getpro/habr/post_images/11f/4c6/f55/11f4c6f554062ec91d1f5d4160b40a43.png",
                "https://habrastorage.org/getpro/habr/post_images/07b/beb/2d7/07bbeb2d7534a3eb062e176c8b059182.png",
                "https://habrastorage.org/getpro/habr/post_images/405/323/e9f/405323e9fad21af9069c1983e25a7025.png"
            ]
        },
        {
            "title": "Оркестрируемая сага или как построить бизнес-транзакции в сервисах с паттерном database per service",
            "text": "Привет! Меня зовут Константин Евтеев, я работаю в Авито руководителем юнита DBA. Наша команда развивает системы хранения данных Авито, помогает в выборе или выдаче баз данных и сопутствующей инфраструктуры, поддерживает Service Level Objective для серверов баз данных, а еще мы отвечаем за эффективность использования ресурсов и мониторинг, консультируем по проектированию, а возможно и разрабатываем микросервисы, сильно завязанные на системы хранения, или сервисы для развития платформы в контексте хранилищ.\r\nЯ хочу рассказать, как мы решили один из вызовов микросервисной архитектуры — проведение бизнес-транзакций в инфраструктуре сервисов, построенных с помощью паттерна Database per service. С докладом на эту тему я выступал на конференции Highload++ Siberia 2018.\r\n\r\n\r\n\r\nТеория. Максимально кратко\r\nЯ не буду подробно описывать теорию саг. Дам лишь краткие вводные, чтобы вы понимали контекст.\r\nКак было раньше (со старта Авито до 2015 – 2016 годов): мы жили в условиях монолита, с монолитными базами и монолитными приложениями. В определенный момент эти условия стали мешать нам расти. С одной стороны, мы уперлись в производительность сервера с главной базой, но это не основная причина, так как вопрос производительности можно решить, например с помощью шардирования. С другой стороны, у монолита очень сложная логика, и на определенном этапе роста доставка изменений (релизов) становится очень длительной и непредсказуемой: много неочевидных и сложных зависимостей (все тесно связано), тестировать тоже трудоемко, в общем масса проблем. Решение — перейти на микросервисную архитектуру. На этом этапе у нас появился вопрос с бизнес транзакциями, сильно завязанными на ACID, предоставленными монолитной базой: нет ясности как мигрировать данную бизнес логику. При работе с Авито возникает множество различных сценариев, реализованных несколькими сервисами, когда целостность и согласованность данных очень важна, например покупка премиальной подписки, списание денег, применение услуг к пользователю, приобретение VAS-пакетов — в случае непредвиденных обстоятельств или аварий все неожиданно может пойти не по плану. Решение мы нашли в сагах.\r\nМне нравится техническое описание саг, которое в 1987 году привели Кеннет Салем и Гектор Гарсия-Молина — один из нынешних членов совета директоров Oracle. Как формулировалась проблема: есть сравнительно небольшое количество долгоживущих транзакций, которые длительное время препятствуют выполнению небольших, менее требовательных к ресурсам и более частых операций. В качестве желаемого результата можно привести пример из жизни: наверняка многие из вас стояли в очереди отксерокопировать документы, и оператор ксерокса, если у него была задача копировать целую книгу или просто много экземпляров копий, время от времени делал копии других членов очереди. Но утилизация ресурсов — это только часть проблем. Ситуацию усугубляют и длительные блокировки при выполнении ресурсоемких задач, каскад из которых выстроится в вашей СУБД. Кроме того, в процессе длительного выполнения транзакции могут возникать ошибки: транзакция не завершится и начнется откат. Если транзакция была длинной, то откат тоже будет идти долго, и вероятно, еще будет retry от приложения. В общем, «все достаточно интересно». Решение, предложенное в техническом описании «SAGAS»: разбить длинную транзакцию на части.\r\nМне кажется, многие подходили к этому, даже не читая этот документ. Мы неоднократно рассказывали про наши defproc (deferred procedures, реализованные при помощи pgq). Например, при блокировке пользователя за fraud — быстро выполняем короткую транзакцию и отвечаем клиенту. В этой короткой транзакции, в том числе, ставим задачу в транзакционную очередь, а потом асинхронно, небольшими партиями, например по десять объявлений блокируем его объявления. Мы это делали с помощью реализации транзакционных очередей от Skype.\r\nНо наша сегодняшняя история немного отличается. Нужно посмотреть на эти проблемы с другой стороны: распил монолита на микросервисы, построенные с помощью паттерна database per service. \r\nОдин из самых важных параметров для нас — достижение максимальной скорости распила. Поэтому мы решили переносить старую функциональность и всю логику как есть в микросервисы, вообще ничего не меняя. Дополнительные требования, которые нам нужно было выполнить:\r\n\r\nобеспечивать зависимые изменения данных для бизнес-критичных данных;\r\nиметь возможность задавать строгий порядок;\r\nсоблюдать стопроцентную консистентность — согласовывать данные даже при авариях;\r\nгарантировать работу транзакций на всех уровнях.\r\n\r\nПод вышеописанные требования наиболее оптимально подходит решение в виде оркестрируемой саги.\r\nРеализация оркестрируемой саги в виде сервиса PG Saga\r\nТак выглядит сервис PG Saga.\r\n\r\nPG в названии, потому что как хранилище сервиса используется синхронный PostgreSQL. Что еще есть внутри: \r\n\r\nAPI;\r\nexecutor;\r\nchecker;\r\nhealthchecker;\r\ncompensator.\r\n\r\nНа схеме также изображен сервис-владелец саг, а внизу — сервисы, которые будут выполнять шаги саги. У них могут быть разные хранилища.\r\nКак это работает\r\nРассмотрим на примере покупки VAS-пакетов. VAS (Values-added services) — платные услуги для продвижения объявления.\r\nСначала сервис владелец саги должен зарегистрировать создание саги в сервисе саг\r\n\r\nПосле этого он генерирует класс саги уже с Payload.\r\n\r\nДалее уже в сервисе саг executor поднимает из хранилища ранее созданный вызов саги и начинает выполнять ее по шагам. Первый шаг в нашем случае — покупка премиальной подписки. В этот момент в сервисе биллинга резервируются деньги.\r\n\r\nПотом в сервисе пользователя применяются VAS-операции.\r\n\r\nЗатем уже действуют VAS-сервисы, и создаются пакеты васов. Дальше возможны и другие шаги, но они не так важны для нас.\r\n\r\nАварии\r\nВ любом сервисе могут произойти аварии, но есть известные приемы, как к ним подготовиться. В распределенной системе об этих приемах знать важно. Например, одно из самых важных ограничений — сеть не всегда надежна. Подходы, которые позволят решить проблемы взаимодействия в распределенных системах:\r\n\r\nДелаем retry.\r\nМаркируем каждую операцию идемпотентным ключом. Это нужно, чтобы избежать дублирования операций. Больше об идемпотентных ключах можно прочитать в этом материале. \r\nКомпенсируем транзакции — действие, характерное для саг. \r\n\r\n\r\nКомпенсация транзакций: как это работает\r\nДля каждой положительной транзакции мы должны описать обратные действия: бизнес-сценарий шага на случай, если что-то пойдет не так.\r\nВ нашей реализации мы предлагаем такой сценарий компенсации:\r\nЕсли какой-то шаг саги завершился неуспешно, а мы сделали множество retry, то есть шанс, что последний повтор операции удался, но мы просто не получили ответ. Попробуем компенсировать транзакцию, хотя этот шаг не обязателен, если сервис-исполнитель проблемного шага действительно сломался и совсем недоступен. \r\nВ нашем примере это будет выглядеть следующим образом:\r\n\r\nВыключаем VAS-пакеты.\r\n\r\n\r\n\r\nОтменяем операцию пользователя.\r\n\r\n\r\n\r\nОтменяем резервирование средств.\r\n\r\n\r\nЧто делать, если и компенсация не работает\r\nОчевидно, что надо действовать по примерно такому же сценарию. Опять применять retry, идемпотентные ключи для компенсирующих транзакций, но если ничего не выходит и в этот раз, например, сервис не доступен, надо обратиться к сервису-владельцу саги, сообщая, что сага сфейлилась. Дальше уже более серьезные действия: эскалировать проблему, например, для ручного разбирательства или запуска автоматики по решению подобных проблем. \r\nЧто еще важно: представьте, что какой-нибудь шаг сервиса саги недоступен. Наверняка же еще инициатор этих действий будет делать какие-то retry. И в итоге, ваш сервис саг делает первый шаг, второй шаг, а его исполнитель недоступен, вы отменяете второй шаг, отменяете первый шаг, а еще могут возникнуть аномалии, связанные с отсутствием изоляции. В общем, сервис саг в этой ситуации занимается бесполезной работой, которая еще порождает нагрузку и ошибки.\r\nКак надо делать? Healthchecker должен опросить сервисы, которые выполняют шаги саг, и посмотреть, работают ли они. Если сервис стал не доступен, то есть два пути: саги, которые в работе, — компенсировать, а новые саги — либо не давать создать новые экземпляры (вызовы), либо создавать, не беря их в работу executer’ом, чтобы сервис не занимался лишними действиями.\r\nЕще один сценарий с аварией\r\nПредставьте, что мы опять делаем ту же самую премиальную подписку.\r\n\r\nПокупаем VAS-пакеты и резервируем деньги.\r\n\r\n\r\n\r\nПрименяем к пользователю услуги.\r\n\r\n\r\n\r\nСоздаем VAS пакеты.\r\n\r\n\r\nВроде бы хорошо. Но внезапно, когда транзакция завершилась, выясняется, что в сервисе пользователей используется асинхронная репликация и на мастер базе произошла авария. Может быть несколько причин отставания реплики: наличие специфичной нагрузки на реплику, которая либо снижает скорость проигрывания репликации, либо блокирует проигрывание репликации. Кроме того, источник (мастер) бывает перегружен, и появляется лаг отправки изменений на стороне источника. В общем, по каким-то причинам реплика отставала, и изменения успешно пройденного шага после аварии внезапно пропали (результат/состояние).\r\n\r\nДля этого реализуем еще один компонент в системе — используем checker. Checker проходит по всем шагам успешных саг через время заведомо большее, чем все возможные отставания (например, через 12 часов), и проверяет, действительно ли они до сих пор успешно выполнены. Если шаг внезапно оказывается не выполнен, сага откатывается. \r\n\r\n\r\n\r\n\r\nМогут быть еще ситуации, когда через 12 часов отменять уже и нечего — все меняется и движется. В таком случае вместо сценария отмены, решением может быть сигнализация сервису владельца саги, что эта операция не выполнилась. Если операция отмены невозможна, скажем, нужно сделать отмену после начисления денег пользователю, а его баланс уже нулевой, и деньги списать нельзя. У нас такие сценарии решаются всегда в сторону пользователя. У вас может быть другой принцип, это согласуется с представителями продукта.\r\nВ итоге, как вы могли заметить, в разных местах для интеграции с сервисом саг нужно реализовать много различной логики. Поэтому когда клиентские команды захотят создать сагу, у них встанет весьма большой набор весьма неочевидных задач. Прежде всего, создаем сагу так, чтобы не получилось дублирования, для этого работаем с какой-то идемпотентной операцией создания саги и ее трекинга. Также в сервисах требуется реализовать способность отслеживать каждый шаг каждой саги, для того чтобы с одной стороны два раза его не выполнить, а с другой стороны, уметь ответить, действительно ли он был выполнен. А еще все эти механизмы надо как-то обслуживать, чтобы хранилища сервисов не переполнились. Кроме того, есть много языков, на которых могут быть написаны сервисы, и огромный выбор хранилищ. На каждом этапе нужно разобраться в теории и имплементировать всю эту логику на разных частях. Если этого не сделать, можно совершить целую кучу ошибок. \r\nПравильных путей много, но ситуаций, когда вы можете «отстрелить себе конечность» — не меньше. Чтобы саги работали корректно, нужно все вышеописанные механизмы инкапсулировать в клиентских библиотеках, которые будут их прозрачно реализовывать для ваших клиентов. \r\nПример логики генерации саги, которую можно скрыть в клиентской библиотеке\r\nМожно сделать иначе, но я предлагаю следующий подход. \r\n\r\nПолучаем request ID, по которому мы должны создать сагу. \r\nИдем в сервис саг, получаем ее уникальный идентификатор, сохраняем его в локальном хранилище в связке с request ID из пункта 1.\r\nЗапускаем сагу с payload в сервис саг. Важный нюанс: я предлагаю локальные операции сервиса, который создает сагу, оформлять, как первый шаг саги.\r\nВозникает некая гонка, когда сервис саг может выполнить этот шаг (пункт 3), и наш backend, инициирующий создание саги, тоже будет его выполнять. Для этого везде делаем идемпотентные операции: кто-то один его выполняет, а второй вызов просто получит «ОК».\r\nВызываем первый шаг (пункт 4) и только после этого отвечаем клиенту, который инициировал это действие.\r\n\r\nВ этом примере мы работаем с сагой как с базой данных. Вы же можете отправить запрос, а далее соединение может и оборвется, но действие будет выполнено. Здесь примерно такой же подход.\r\nКак это все проверить\r\nНужно покрыть весь сервис саг тестами. Вероятнее всего, вы будете вносить изменения, и тесты, написанные на старте, помогут избежать нежданных сюрпризов. Кроме того, необходимо проверять и сами саги. Например, как у нас устроено тестирование сервиса саг и тестирование последовательности саг в рамках одной транзакции. Тут есть разные блоки тестов. Если мы говорим про сервис саг, он умеет выполнять положительные транзакции и транзакции компенсации, если компенсация не работает сообщает сервису владельцу саг. Мы пишем тесты в общем виде, на работу с абстрактной сагой.\r\nС другой стороны, положительные транзакции и компенсационные транзакции на сервисах, которые выполняют шаги саг, это же простое API, и тесты этой части в зоне ответственности команды-владельца этого сервиса.\r\nА далее уже команда владелец саги пишет end-to-end тесты, где она проверяет, что вся бизнес-логика корректно работает при выполнении саги. Еnd-to-end тест проходит на полноценном dev-окружении, поднимаются все экземпляры сервисов, в том числе сервис саг, и там уже проходит проверку бизнес-сценарий.\r\n\r\nИтого:\r\n\r\nнаписать побольше юнит-тестов;\r\nнаписать интеграционные тесты;\r\nнаписать end-to-end тесты.\r\n\r\nСледующий шаг — CDC. Микросервисная архитектура влияет на специфику тестов. В Авито мы приняли следующий подход к тестированию микросервисной архитектуры: Consumer-Driven Contracts. Этот подход помогает, прежде всего, подсветить проблемы, которые можно выявить на end-to-end тестах, но end-to-end тест «очень дорогой».\r\n\r\nВ чем суть CDC? Есть сервис, который предоставляет контракт. У него есть API — это provider. А есть другой сервис, который вызывает API, то есть пользуется контрактом — consumer.\r\nСервис-consumer пишет тесты на контракт provider’а, причем тесты, которые будет проверять только контракт, — не функциональные тесты. Нам важно гарантировать, что при изменении API у нас не сломаются шаги в данном контексте. После того как мы написали тесты, появляется еще один элемент сервис-брокер — в нем регистрируется информация о CDC-тестах. При каждом изменении сервиса провайдера он будет поднимать изолированное окружение и запускать тесты, которые написал consumer. Что в итоге: команда, которая генерирует саги, пишет тесты на все шаги саги и регистрирует их. \r\n\r\nО том, как в Авито реализовали CDC-подход для тестирования микросервисов рассказывал Фрол Крючков на РИТ++. Тезисы можно найти на сайте Backend.conf — рекомендую ознакомиться. \r\nВиды саг\r\nПо порядку вызова функций\r\nа) неупорядоченная — функции саги вызываются в любом порядке и не ждут завершения друг друга;\r\nб) упорядоченная — функции саги вызываются в заданном порядке, друг за другом, следующая не вызывается пока не завершится предыдущая;\r\nв) смешанная — для части функций задан порядок, а для части нет, но задано перед или после каких этапов их выполнять.\r\nРассмотрим конкретный сценарий. В том же сценарии покупки премиальной подписки первым шагом будет резервирование денег. Теперь изменения у пользователя и создание премиальных пакетов мы можем выполнить параллельно, а пользователю отправим уведомления только когда закончатся эти два шага.\r\n\r\nПо получению результата вызова функций\r\nа) синхронная — результат функции известен сразу;\r\nб) асинхронная — функция возвращает сразу «ОК», а результат возвращается потом, через обратный вызов API сервиса саг из клиентского сервиса.\r\nХочу вас предостеречь от ошибки: лучше не делать синхронные шаги саг, особенно при реализации оркестрируемой саги. Если вы будете делать синхронные шаги саг, то сервис саг будет ждать, пока выполниться этот шаг. Это лишняя нагрузка, лишние проблемы в сервисе саг, поскольку он один, а участников саг много.\r\nМасштабирование саг\r\nМасштабирование зависит от размеров планируемой вами системы. Рассмотрим вариант с одним экземпляром хранилища:\r\n\r\nодин обработчик шагов саг, обрабатываем шаги батчами;\r\nn обработчиков, реализуем «расческу» — берем шаги по остатку от деления: когда каждый executor получает свои шаги. \r\nn обработчиков и skip locked — будет еще эффективнее и более гибко.\r\n\r\nИ только потом, если вы заранее знаете, что упретесь в производительность одного сервера в СУБД, нужно делать шардинг — n инстансов баз, которые будут работать со своим набором данных. Шардирование можно скрыть за API сервиса саг.\r\nБольше гибкости\r\nКроме того, в этом паттерне, по крайней мере в теории, клиентский сервис (выполняющий шаг саги) может обращаться к сервису саг и вписываться в него, а участие в саге может быть в том числе и опциональным. Еще может быть и другой сценарий: если вы уже отправили электронное письмо, компенсировать действие невозможно — вернуть письмо назад нельзя. Но можно отправить новое письмо, что предыдущее было неправильным, и выглядит подобное так себе. Лучше использовать сценарий, когда сага будет проигрываться только вперед, без каких-либо компенсаций. Если она не проигрывается вперед, то надо сообщать сервису владельцу саги о проблеме.\r\nКогда нужен лок\r\nНебольшое отступление про саги в целом: если вы можете сделать свою логику без саги, то делайте. Саги — это сложно. С локом примерно то же самое: лучше всегда избегать блокировок.\r\nКогда я пришел в команду биллинга рассказывать про саги, они сказали, что им нужен лок. У меня получилось им объяснить, почему лучше обойтись без него и как это сделать. Но если лок все-таки вам потребуется, то это стоит предусмотреть заранее. До сервиса саг мы уже в рамках одной СУБД реализовывали блокировки. Пример с defproc и сценарием асинхронной блокировки объявлений и синхронной блокировкой аккаунта, когда сначала синхронно делаем часть операции и ставим блокировку, а потом асинхронно в фоне завершаем батчами оставшуюся работу.\r\nКак это сделать? В рамках одной СУБД вы можете сделать некую таблицу, в которой будете сохранять записи о блокировке, и далее в триггере, при выполнении операций над объектом этой блокировки подсматривать в эту таблицу, и, если кто-то попытается его поменять во время блокировки, генерировать исключения. Примерно то же самое можно сделать и в сервисе саг. Главное соблюсти порядок. Я предлагаю следующий подход: сначала мы делаем блокировку в сервисе саг, если мы хотим реализовать сагу с локом, а потом уже ее спускаем до клиентского сервиса с помощью вышеописанного подхода.\r\nМожно и по-другому, но важно, чтобы был правильный порядок. И нужно понимать, что если у вас появились блокировки, значит появятся и дедлоки. Если появятся дедлоки, значит, нужно делать детектор дедлоков. А еще блокировки могут быть эксклюзивные и разделяемые. Но не советую планировать многоуровневую блокировку — это достаточно сложная история, а сервис должен быть простым, ведь он единственная точка отказа всех ваших транзакций. \r\nACID — без изоляции\r\nУ нас есть атомарность, поскольку все шаги либо выполнятся, либо компенсируются. Есть консистентность за счет сервиса саг и локальных хранилищ в сервисе саг. И устойчивость — благодаря локальным хранилищам и их механизмам durability. Изоляции у нас нет. В отсутствие изоляции у нас будут возникать различные аномалии. Они возникнут, когда мы можем потерять обновления. Вы прочитаете какие-то данные, потом кто-то другой что-то запишет, а ваша исходная транзакция возьмет и перепишет эти изменения\r\n\r\nМогут происходит грязные чтения — когда вы в процессе выполняете какую-то сагу, сделали что-то одно, записали, кто-то эти изменения уже прочитал, а ваша сага еще не закончена. Вы записываете еще раз, что-то меняете, а кто-то прочитает неправильные состояния.\r\n\r\nСлучаются неповторяющиеся чтения — когда вы в течение одной и той же саги будете получать разные состояния вашего объекта.\r\n\r\nКак этого избежать:\r\n\r\nРаботать с версией объекта, держать некую версию, например, у пользователя, и ее инкрементировать при каждом изменении. \r\nПроверять, что вы все еще работаете с ней же. Или же смотреть то состояние, которое вы хотите поменять, например статус, и следить, что вы применяете его к тому самому статусу, который до этого хотели сменить.\r\nМожно выстроить блокировки и сериализовывать все изменения вокруг главного объекта саги.\r\nПередавать в payload саги только события и не работать с состоянием. Эта история об eventual consistency — если вы передадите состояние объявления сервису пользователей, может быть, оно уже поменяется к тому моменту, когда событие дойдет до адресата. Нужно передавать информацию о том, что произошла, например, регистрация пользователей или мы применили пользователю премиум-услугу. \r\n\r\n\r\nМониторинг\r\nНужно мониторить выполнение саг с разбивкой по всем шагам и по всем статусам. Мы собираем всю телеметрию, в том числе как долго выполняется каждый шаг саги и сами саги. Все то же самое мы должны смотреть и для компенсирующих транзакций. К тому же не забывать про checker. А еще хорошо бы обложить сервис саг метриками на каждом шаге. Вот примеры графиков, которые мы собираем.\r\n\r\n\r\nВ первую очередь смотрим на перцентили (50%, 75%, 95%, 99%), потому что по ним вы раньше всего узнаете, если что-то пошло не так. \r\nКак определить место поломки, если сага поломалась — как я уже сказал, мы собираем метрики с разбивкой по шагам и далее. На все эти шаги саг мы можем повесить алерты. Если определенные шаги саги копятся, значит что-то пошло не так. Но возможно, что сага еще совсем не сломалась — просто произошел всплеск нагрузки в одном из сервисов исполнителей шагов саги.\r\nЕще одна ситуация. Как определить, что какой-то шаг саги (сервис вышел из строя) совсем не работает. В данном случае healthchecker проверяет все endpoint’ы info (keep-alive) клиентских сервисов.\r\nНу и третий пример. Может быть авария со стороны бизнес-сценария. Ответственность бизнес-сценария, что ваша бизнес-транзакция выполняется корректно, уже полностью лежит на команде владельца саги и командах владельцев сервисов-исполнителей шагов саги. В этой ситуации владелец отдельно взятой саги, когда он ее проектирует, должен покрыть ее тестами, в том числе end-to-end. Далее нужен мониторинг на различные бизнес-метрики саги. Команда, которая сгенерировала эту сагу, должна у себя отслеживать метрики — это зона ее ответственности.\r\nСам сервис саг также тщательно мониторим. А еще хорошо бы реализовать автофейловер для локального хранилища сервиса саг. \r\nНа что стоит обратить внимание:\r\nИзбегать паразитных нагрузок\r\nВыше я уже говорил, что нужно строить healthchecker, и если какой-то узел вышел из строя, нужно прекращать выполнять эти саги. Потому что сервис саг один, а клиентов много. Вы просто излишне перегрузите ваш сервис саг.\r\nИзбегать сложной логики избыточной функциональности в сервисе саг\r\nКак только вы ввязываетесь в эту историю, сервис саг становится самой критичной точкой вашей инфраструктуры. Если он откажет, последствия могут быть ровно такими, какую вы функциональность на него накрутите. А мы хотим на него завязать самую критичную функциональность. Поэтому choreography паттерн саг смотрится выгоднее — там сервис саг участвует только когда что-то пошло не так. В общем виде, даже если ваш сервис саг в choreography-паттерне сломается, у вас все будет продолжать работать. Сервис саг в choreography критически нужен, например при выполнении отката. Если мы делаем оркестрируемую сагу, то с выходом из строя сервиса саг из строя выйдет все. Соответственно, чем меньше логики вы туда вкрутите, тем проще и быстрее он будет работать, и тем надежнее будет вся система.\r\nИнтегрироваться с клиентами\r\nОбучить все ваши команды работе с сервисом саг. Этот пласт теории надо прочитать, поскольку не всем может быть очевидно, как правильно работать с персистентными системами в контексте саг. Подумайте, как сделать удобной работу с локальным хранилищем + работу с различными языками в контексте саг и как это все скрыть в клиентских библиотеках.\r\nВерсионность API\r\nВ нашей реализации, когда в сервисе-исполнителе клиентского шага мы хотим что-то поменять (новая версия API сервиса), мы создаем новую сагу, в которой используем новую версию API. После этого переводим всех на новую сагу и старую сагу можно удалять и далее старый метод API также можно удалить. Тут нужно быть внимательным — изменения в том числе могут неявно затрагивать логику компенсации. В том числе перед удалением старых классов саг и методов API шагов саг, нужно подождать интервал времени, когда уже 100% по старым методам не может пройти компенсация.\r\nНу и естественно, если придется менять сервис саг, и изменения будут обратно несовместимыми, необходимо будет поправить все сервисы, которые взаимодействуют с сервисом саг. Серебряной пули нет — все зависит от того, насколько велик характер изменений, которые вы собираетесь внести. Но таких случаев у нас пока не было.\r\nКомпенсация при авариях\r\nПри проектировании компенсационных транзакций, в случае различных аварий, когда невозможно выполнить сагу, внимательно изучите с представителем продукта вероятные сценарии и опишите их. Важно искать компромисс между автоматизацией решения инцидентов (предпочтительный вариант) и передачей их на анализ и принятие решения человеком.\r\nОтсутствие изоляции\r\nЛучше заранее изучить различные сценарии, кто работает с тем или иным объектом вашей саги или частью саги, конкретного шага, и что может пойти не так, если он прочитает данные в процессе выполнения саги.\r\nБлокировки\r\nЛучше их избегать. Скорее всего, если не получается это сделать, вам нужен другой инструмент.\r\nТрейсинг по saga call ID\r\nУ нас все состояния хранятся в хранилище сервиса саг. Есть API в сервисе саг, которое по идентификатору конкретного экземпляра саги возвращает текущее состояние саги. \r\nИтог — что выбирать\r\nСагу-оркестратор мы используем как возможность рефакторинга legacy кода. Но если бы была возможность написания всего с нуля, мы использовали бы хореографическую сагу (в том числе в планах реализация паттерна «хореограф» и перевода на него части функциональности но это уже другая история и там есть свои нюансы). Что тут является «узким горлышком»? Если вы хотите как-то поменять сагу, вам надо пойти к команде, которая владеет этой сагой, договориться о том, что вы собираетесь что-то менять, потому что у нее в том числе тесты могут быть. Но в любом случае вам, как минимум, надо с ними договориться или законтрибьютить в их сервис тот код, который теперь будет генерировать сагу с вашим дополнительным шагом. И таким образом получается, что это достаточно «узкое горлышко», потому что очень плохо масштабируется, если у вас очень много команд и различной бизнес-логики. Это минус. Плюс — это удобство переноса текущей функциональности. Все потому, что мы можем заранее жестче тестировать и гарантировать порядок выполнения. \r\nЯ за прагматичный подход к разработке, поэтому для написания сервиса саг, инвестиция в написание такого сервиса должна быть оправдана. Более того, вероятнее всего, многим нужна только часть из того, что я описал, и эта часть решит текущие потребности. Главное, заранее понять, что именно из всего этого нужно. И как много ресурсов у вас есть.\r\nЕсли у вас есть вопросы или вам интересно узнать больше про саги, пишите в комментариях. С радостью отвечу.",
            "images": [
                "https://habrastorage.org/webt/r3/bz/ty/r3bztya5eso1a_fkh9laghkue9k.png",
                "https://habrastorage.org/webt/mi/zm/0f/mizm0fidaxgpcv3wxoway4ksgoe.jpeg",
                "https://habrastorage.org/webt/6d/yo/zs/6dyozsxy0_qfoqmrtlrbijfaxeu.jpeg",
                "https://habrastorage.org/webt/ul/hr/ic/ulhric8ofs455lgaz4mozdhs2l8.jpeg",
                "https://habrastorage.org/webt/hf/re/yi/hfreyiq0vpgiojytn2gts5ws1ww.jpeg",
                "https://habrastorage.org/webt/cy/lg/_m/cylg_mbibq4b6wfqvu_wz7ylcre.jpeg",
                "https://habrastorage.org/webt/h6/3r/r8/h63rr8iufd3m4tzovgonjywezhu.jpeg",
                "https://habrastorage.org/webt/rf/6s/94/rf6s943lzidqq_hfyuu-_fnbd_a.jpeg",
                "https://habrastorage.org/webt/qv/wl/tx/qvwltxbftjc_diwxtudv5ym0mde.jpeg",
                "https://habrastorage.org/webt/0b/_r/t9/0b_rt9gobty3zu1xhz6uqjo2cf8.jpeg",
                "https://habrastorage.org/webt/tn/ms/7p/tnms7pcslyj_8f4hftsqtzzlspm.jpeg",
                "https://habrastorage.org/webt/by/ep/fe/byepfee_drperqqj2on1hg3gq-a.jpeg",
                "https://habrastorage.org/webt/yq/l_/sf/yql_sf9gnlyolfstvyug4gwaday.jpeg",
                "https://habrastorage.org/webt/hu/nh/hu/hunhhuizvvxmajf0hukmvbhzpnu.jpeg",
                "https://habrastorage.org/webt/kn/9n/cy/kn9ncyccg350yxl-orc9jamngbm.jpeg",
                "https://habrastorage.org/webt/hz/af/-m/hzaf-mwke2a8cvi8mdlb_uzquxy.jpeg",
                "https://habrastorage.org/webt/jg/ex/dc/jgexdcrgimsuugdqw27gay_i2kw.jpeg",
                "https://habrastorage.org/webt/xp/hv/mo/xphvmouowjv2tgln0-o1mf43rts.jpeg",
                "https://habrastorage.org/webt/qb/j0/gn/qbj0gnyhcjvk2lz4djeip_qfaqe.png",
                "https://habrastorage.org/webt/n1/i-/hm/n1i-hmjmyxs9iavcoxzoem2mcly.jpeg",
                "https://habrastorage.org/webt/d8/a0/r7/d8a0r7wv7mq1a8gdphaq0aug1oe.png",
                "https://habrastorage.org/getpro/habr/formulas/75e/3da/36e/75e3da36edd7f353360d316d857b6973.svg",
                "https://habrastorage.org/getpro/habr/formulas/330/0db/27c/3300db27c92f485873cebc526ac445f1.svg",
                "https://habrastorage.org/getpro/habr/formulas/672/e6d/3b5/672e6d3b50fdeabfe79f8de34acf5241.svg",
                "https://habrastorage.org/webt/vm/gv/_w/vmgv_wl16ngyd78b78ndyp4v1_4.png",
                "https://habrastorage.org/webt/fv/cz/2l/fvcz2luhdac4ixpzmlbbarex_se.png"
            ]
        },
        {
            "title": "Как единственная строка древнего кода целых полгода сводила с ума разработчиков MMORPG",
            "text": "\r\nЧаще всего от разработчиков игр можно услышать очень простую фразу: удивительно, что игры вообще выходят. Игры — это усложнённые, неприручённые чудовища, соединённые чем-то вроде цифровой изоленты. Не удивительно, что они разваливаются на части.\r\n\r\nAliens: Colonial Marines была проблемной по многим причинам, но быстро стала всеобщим посмешищем, когда появились подобные виральные клипы, в которых ксеноморфы бессмысленно бродят по уровням. В этом месяце разработчик модов обнаружил, что причиной глупейшего поведения ИИ «чужих» стала одна ошибка в коде игры. (Об этом была статья на Хабре.) Упс. Но это не единственный случай за этот год, когда игра оказывалась унижена из-за упущенной клавиатурной опечатки. В начале 2018 года фанаты обнаружили, что ИИ Civilization VI подозрительно ударяется в религию: дело оказалось в том, что слово «yield» в коде было написано как «yeild».\r\n\r\nПоэтому неудивительно узнать, что в разработке игр полно таких моментов.\r\n\r\nЛеа Миллер несколько лет работала дизайнером в бывшем разработчике MMO-игр Mythic Entertainment. Она занималась сценариями, дизайном контента и систем для  Dark Age of Camelot и  Warhammer Online: Age of Reckoning. В момент выпуска студия стала получать от фанатов жалобы: игра казалась медленной и малоотзывчивой. Игроки не могли определить, в чём конкретно была причина.\r\n\r\nЭто было просто… ощущение?\r\n\r\n«Команда разработчиков пересмотрела систему боя, чтобы он ощущался более быстрым, и искала неэффективные операции на стороне сервера, от которых можно было избавиться», — рассказывает Миллер. «Но всё равно отзывы были слишком расплывчатыми, никто не мог сказать точно, в чём причина. Был ли это недостаток в общем дизайне игры? Вносилось множество изменений, чтобы улучшить ощущения от игры, и хотя многие из них были настоящими улучшениями, корень всех проблем устранить не удалось».\r\n\r\n\r\nWarhammer Online не собрал большую аудиторию и в результате был закрыт в 2013 году.\r\n\r\nКопаясь в коде полгода, команда разработчиков так и не могла найти решение.\r\n\r\nОдин из относительно новых программистов изучал код Age of Reckoning и обнаружил нечто странное. В нём по-прежнему оставалась строка, относившаяся к предыдущей MMO студии,  Dark Age of Camelot. Она выполняла обработку игроков на дайлапе. Да, на дайлапе.  Dark Age of Camelot была выпущена в 2001 году, в эпоху, когда широкополосное подключение ещё не стало стандартом. В то время игрокам приходилось следить, чтобы никто не поднимал телефонную трубку, иначе соединение разрывалось. (День, когда моя семья купила модем на 56K, был волшебным.)\r\n\r\n«Он довольно недавно работал в компании и не был знаком с кодом», — рассказывает Миллер. «И возможно поэтому он изучал этот фрагмент более внимательно, чем остальные до него».\r\n\r\nПосле удаления строки проблема исчезла. Игра снова стала плавной.\r\n\r\nТак что же произошло? В наши дни компьютеры мощны, а Интернет быстр. Но в начале эпохи MMO всё было иначе, то есть играм приходилось идти на компромиссы.\r\n\r\n«В сетевом коде  Dark Age of Camelot была единственная строка, искусственно замедлявшая частоту передачи определённого типа данных клиентом и сервером», — объясняет Миллер. «Полагаю, основная цель этого заключалась в оптимизации загрузки сети, однако возможно это была часть системы, предназначенной для того, чтобы подключающиеся по дайлапу игроки были конкурентоспособны в PvP. Эта задержка была почти незаметна для игроков в Dark Age of Camelot, потому что боёвка игры была подстроена под стандартную ширину полосы и вычислительные мощности той эры. Только у очень малой доли игроков были системы, способные обрабатывать данные быстрее, чем они отправлялись и принимались».\r\n\r\n\r\nВ отличие от Warhammer Online, Dark Age of Camelot по-прежнему на плаву.\r\n\r\nВ процессе развития Dark Age of Camelot его сетевой код тоже эволюционировал и занимался такими функциями, как управление пиковыми значениями задержек, вход на серверы и другими задачами. Спустя десятилетие работы Dark Age of Camelot студия Mythic решила перенести тот же код в Age of Reckoning.\r\n\r\nКак оказалось, он сломал функционал в совершенно неожиданном месте.\r\n\r\nК тому времени, когда Mythic устранила проблему, большинство игроков вернулось обратно к World of Warcraft. Этот баг не был единственной причиной проблем Age of Reckoning, но он внёс в них свой вклад.\r\n\r\nМиллер написала мне, когда я публично попросил в Twitter рассказать о других ужасных историях, даже если примеры касались не только таких нелепостей, как опечатки. Дискуссия совпала с обсуждениями в других кругах после инцидента с Colonial Marines, и мне хотелось бы поделиться самыми выдающимися историями.\r\n\r\nLiterally every single time I type the word \"acquired\" I have a PTSD flashback to Deus Ex 2 where we had a misspelled asset directory called AquiredDataText that we could never ever rename so I typed \"aquired\" for three years.— Brian Sharp (@bhsharp) June 29, 2018\n\n\r\nБрайан Шарп: Буквально каждый раз, когда пишу слово «acquired», я испытываю посттравматический флешбэк с Deus Ex 2, в котором мы ошибочно назвали папку с ресурсами AquiredDataText, и не могли её переименовать. Мне пришлось три года подряд писать «aquired».\r\n\r\nRight before launch of Undead Nightmare, the script on the zombie bait dynamite got a misplaced comment in the iterator that directed \"actors\" to walk to it. So, uh, it suddenly started working on Marston himself.Plot twist!— Trick Dempsey (@TrickDempsey) July 17, 2018\n\n\r\nТрик Демпси: Прямо перед выпуском Red Dead Redemption: Undead Nightmare в итераторе скрипта динамитной приманки для зомби была раскомментирована строка, направлявшая акторов прямо на приманку. Поэтому она внезапно стала срабатывать и на самого Марстона (главного героя).\r\nНеожиданный поворот сюжета!\r\n\r\nI shipped a game on PSP (so before patches) that would 100% crash on load if it was a leap year...— Matt Lacey (@LaceMattley) July 14, 2018\n\n\r\nМэтт Лейси: Я выпустил игру на PSP (то есть без возможности её пропатчить), которая стопроцентно крашилась, если год был високосным...\r\n\r\nTypos that are enshrined into code are INCREDIBLY common. They're also hard to remove in many cases because you have to consistently rename everything that uses the typo in order to not introduce new bugs.This is why the medical stats software I work on has Surigcal all over— Ailie (@cenuji) July 17, 2018\n\n\r\nЭйли: навеки оставшиеся в коде опечатки встречаются НЕВЕРОЯТНО часто. Кроме того, очень часто их сложно устранить, ведь чтобы не добавлять новых багов, нужно постоянно всё переименовывать. Именно поэтому в медицинском ПО, над которым я работаю, повсюду встречается слово Surigcal (вместо Surgical).\r\n\r\nI was once in a huge demo and pressed a button while saying \"now you'll see a blue ball\" as a giant green ball appeared. Forgot to call the apply function. Tried to talk my way out of it but nobody bought it.— Andrew Eiche (@buddingmonkey) July 14, 2018\n\n\r\nЭндрю Эйке: однажды я был на серьёзном демо-показе, нажал на кнопку со словами «сейчас вы увидите синий шар», и появился огромный зелёный шар. Я забыл применить функцию. Попробовал заболтать этот фейл, но никто не купился.\r\n\r\nA few days ago, @cukiakimani reports Semblance was suddenly running at 19 Frames Per Second out of nowhere. Turns out 1 line of my code was consuming 41 FPS. I found that absolutely hilarious. pic.twitter.com/V21hLfmrTg— South African Articulate Dolph Ziggler (@_benjamming) January 12, 2018\n\n\r\nДольф Зиглер: Несколько дней назад @cukiakimani сообщил мне, что игра Semblance внезапно начала работать при 19 кадрах в секунду. \r\n\r\nОказалось, что одна строка моего кода пожирает 41 FPS. Мне кажется, это совершенно восхитительно.\r\n\r\nI had a project due at midnight but it wasn’t working right. i had an hour left, i had waited for a ta for 3 hours, and i was ready to cry. TA finally comes over, looks at my code for 30 seconds, tells me to change one variable on one line. It runs perfectly.— Trying his Best (@Willipossiblyam) July 14, 2018\n\n\r\nTrying his Best: У меня был проект, который требовалось закончить к полуночи, но он не работал правильно. Оставался всего час, я ждал ассистента преподавателя уже три часа и был готов расплакаться. Наконец ассистент пришёл, полминуты посмотрел на мой код и сказал изменить одну переменную в одной строке. Всё заработало идеально.\r\n\r\nЯ бы хотел выделить одну опечатку, которая просто взорвала мой мозг.\r\n\r\nВ детстве я был одержим Super Mario 64. Это была первая игра, в которую я играл на японском, спасибо магазину импорта, находившемуся рядом с кинотеатром, в который мы часто ходили. (Они брали с людей деньги за час игры в импортную копию первого 3D-платформера про Марио! И оно того стоило.) Когда мне наконец удалось приобрести домой собственную копию Super Mario 64, я был одним из того множества людей, которые в процессе сбора 120 звёзд и поиска Йоши недоумевали, почему так невероятно сложно проплыть через подводные кольца. И причина нашлась!\r\n\r\nYou see this in a few Mario games. Lakitu was supposed to throw spinies directly at you in Super Mario Bros., but a typo in the code prevented him from aiming. And there's this bug in Super Mario 64:https://t.co/GddMkpMZh4— Vincent Kinian (@Video_Game_King) July 17, 2018\n\n\r\nВинсент Киниан: Этот баг можно увидеть в нескольких играх про Марио. В Super Mario Bros. Лакиту должен был бросать шипастых черепах Spiny прямо в игрока, но из-за опечатки в коде этого не происходило. А вот этот баг в Super Mario 64: https://t.co/GddMkpMZh4.\r\n\r\nПотрясающе. Непонятно, как видеоигры вообще существуют.",
            "images": [
                "https://habrastorage.org/getpro/habr/post_images/994/61e/bbf/99461ebbff8a40ea51f15d7b00ab075f.jpg",
                "https://habrastorage.org/getpro/habr/post_images/563/861/0c2/5638610c2536fe868d842dc0f147452b.jpg",
                "https://habrastorage.org/getpro/habr/post_images/c36/609/979/c36609979079c464fdaad1eabc3ed9a5.jpg"
            ]
        },
        {
            "title": "Насколько эффективна виртуальная файловая система procfs и можно ли ее оптимизировать",
            "text": "Файловая система proc (в дальнейшем просто procfs) является виртуальной файловой системой, которая предоставляет информацию о процессах. Она — “прекрасный” пример интерфейсов следующих парадигме “все является файлом”. Procfs была разработана очень давно: во времена, когда серверы в среднем обслуживали несколько десятков процессов, когда открыть файл и вычитать информацию о процессе не было проблемой. Однако время не стоит на месте, и сейчас серверы обслуживают сотни тысяч, а то и больше процессов одновременно. В таком контексте идея “открыть файл для каждого процесса, чтобы вычитать интересующие данные” уже не выглядит такой привлекательной, и первое что приходит на ум чтобы ускорить чтение — это получение информации о группе процессов за одну итерацию. В этой статье мы попробуем найти элементы procfs которые можно оптимизировать.\r\n\r\nСама мысль улучшить procfs возникла когда мы обнаружили, что CRIU тратит значительное количество времени просто читая procfs файлы. Мы видели как подобная проблема была решена для сокетов, и решили сделать что-то похожее на sock-diag интерфейс, но только для procfs. Конечно мы предполагали, насколько сложно будет поменять давнишний и вполне устоявшийся интерфейс в ядре, убедить сообщество, что игра стоит свеч… и были приятно удивлены количеством людей, которые поддержали создание нового интерфейса. Строго говоря, никто не знал, как должен выглядеть новый интерфейс, но сомнений в том, что procfs не удовлетворяет текущим требованиям по производительности нет. Например такой сценарий: сервер отвечает на запросы слишком долго, vmstat показывает, что память ушла в своп, а запуск “ps ax” выполняется от 10 секунд и более, top и вовсе ничего не показывает. В этой статье мы не будем рассматривать какой-то конкретный новый интерфейс, скорее попробуем описать проблемы и пути их решения.\r\nКаждый исполняющийся процесс procfs представляет директорией /proc/<pid>.\r\nВ каждой такой директории множество файлов и поддиректорий, которые предоставляют доступ к определенной информации о процессе. Поддиректории группируют данные по признакам. Например ($$ это специальная переменная оболочки, которая раскрывается в pid — идентификатор текущего процесса):\r\n$ ls -F /proc/$$\nattr/            exe@        mounts         projid_map    status\nautogroup        fd/         mountstats     root@         syscall\nauxv             fdinfo/     net/           sched         task/\ncgroup           gid_map     ns/            schedstat     timers\nclear_refs       io          numa_maps      sessionid     timerslack_ns\ncmdline          limits      oom_adj        setgroups     uid_map\ncomm             loginuid    oom_score      smaps         wchan\ncoredump_filter  map_files/  oom_score_adj  smaps_rollup\ncpuset           maps        pagemap        stack\ncwd@             mem         patch_state    stat\nenviron          mountinfo   personality    statm\r\nВсе эти файлы выдают данные в разных форматах. Большинство в формате ASCII текста, который легко воспринимается человеком. Ну почти легко:\r\n$ cat /proc/$$/stat\n24293 (bash) S 21811 24293 24293 34854 24876 4210688 6325 19702 0 10 15 7 33 35 20 0 1 0 47892016 135487488 3388 18446744073709551615 94447405350912 94447406416132 140729719486816 0 0 0 65536 3670020 1266777851 1 0 0 17 2 0 0 0 0 0 94447408516528 94447408563556 94447429677056 140729719494655 140729719494660 140729719494660 140729719496686 0\r\nЧтобы понять, что значит каждый элемент этого множества, читателю придется открыть man proc(5), либо документацию ядра. Например, второй элемент — это имя исполняемого файла в скобках, а девятнадцатый элемент — это текущее значение приоритета исполнения (nice).\r\nНекоторые файлы вполне читабельны сами по себе:\r\n$ cat /proc/$$/status | head -n 5\nName:   bash\nUmask:  0002\nState:  S (sleeping)\nTgid:   24293\nNgid:   0\r\nНо как часто пользователи читают информацию напрямую из файлов procfs? Сколько времени нужно ядру чтобы перевести бинарные данные в текстовый формат? Какие накладные расходы у procfs? Насколько удобен такой интерфейс для программ мониторов состояния, и сколько времени они тратят чтобы обработать эти текстовые данные? Насколько критична такая медленная реализация в аварийных ситуациях?\r\nСкорее всего, не будет ошибкой сказать, что пользователи предпочитают программы типа top или ps, вместо того, чтобы читать данные из procfs напрямую.\r\nДля ответа на остальные вопросы проведем несколько экспериментов. Во-первых, найдем где именно ядро тратит время, чтобы сгенерировать файлы procfs.\r\nЧтобы получить определенную информацию у всех процессов в системе, нам придется пройти по директории /proc/ и выбрать все поддиректории, имя которых представлено десятичными цифрами. Затем, в каждой из них, нам необходимо открыть файл, прочитать его и закрыть.\r\nСуммарно мы исполним три системных вызова, причем один из них создаст файловый дескриптор (в ядре файловый дескриптор ассоциируется с набором внутренних объектов, для которых выделяется дополнительная память). Системные вызовы open() и close() сами по себе не дают нам никакой информации, так что их можно отнести к накладным расходам интерфейса procfs.\r\nПопробуем просто сделать open() и close() для каждого процесса в системе, но не будем читать содержимое файлов:\r\n$ time ./task_proc_all --noread stat\ntasks: 50290\n\nreal    0m0.177s\nuser    0m0.012s\nsys 0m0.162s\r\n$ time ./task_proc_all --noread loginuid\ntasks: 50289\n\nreal    0m0.176s\nuser    0m0.026s\nsys 0m0.145\r\ntask-proc-all — небольшая утилита, с кодом которой можно ознакомится по ссылке снизу\r\nНеважно какой именно файл открыть, поскольку реальные данные генерируются только в момент read().\r\nА теперь посмотрим на вывод профилировщика ядра perf:\r\n-   92.18%     0.00%  task_proc_all    [unknown]\n   - 0x8000\n      - 64.01% __GI___libc_open\n         - 50.71% entry_SYSCALL_64_fastpath\n            - do_sys_open\n               - 48.63% do_filp_open\n                  - path_openat\n                     - 19.60% link_path_walk\n                        - 14.23% walk_component\n                           - 13.87% lookup_fast\n                              - 7.55% pid_revalidate\n                                   4.13% get_pid_task\n                                 + 1.58% security_task_to_inode\n                                   1.10% task_dump_owner\n                                3.63% __d_lookup_rcu\n                        + 3.42% security_inode_permission\n                     + 14.76% proc_pident_lookup\n                     + 4.39% d_alloc_parallel\n                     + 2.93% get_empty_filp\n                     + 2.43% lookup_fast\n                     + 0.98% do_dentry_open\n           2.07% syscall_return_via_sysret\n           1.60% 0xfffffe000008a01b\n           0.97% kmem_cache_alloc\n           0.61% 0xfffffe000008a01e\n      - 16.45% __getdents64\n         - 15.11% entry_SYSCALL_64_fastpath\n              sys_getdents\n              iterate_dir\n            - proc_pid_readdir\n               - 7.18% proc_fill_cache\n                  + 3.53% d_lookup\n                    1.59% filldir\n               + 6.82% next_tgid\n               + 0.61% snprintf\n      - 9.89% __close\n         + 4.03% entry_SYSCALL_64_fastpath\n           0.98% syscall_return_via_sysret\n           0.85% 0xfffffe000008a01b\n           0.61% 0xfffffe000008a01e\n        1.10% syscall_return_via_sysret\r\nЯдро тратит почти 75% времени просто чтобы создать и удалить файловый дескриптор, и около 16% чтобы вывести список процессов.\r\nХотя мы и знаем сколько времени нужно на вызовы open() и close() для каждого процесса, мы пока не можем оценить насколько оно значительно. Нам надо сравнить полученные величины с чем-то. Попробуем сделать тоже самое с наиболее известными файлами. Обычно, когда надо вывести список процессов, используется утилита ps или top. Они обе читают /proc/<pid>/stat и /proc/<pid>/status для каждого процесса в системе.\r\nНачнем с /proc/<pid>/status — это массивный файл с фиксированным количеством полей:\r\n$ time ./task_proc_all status\ntasks: 50283\n\nreal    0m0.455s\nuser    0m0.033s\nsys 0m0.417s\r\n-   93.84%     0.00%  task_proc_all    [unknown]                   [k] 0x0000000000008000\n   - 0x8000\n      - 61.20% read\n         - 53.06% entry_SYSCALL_64_fastpath\n            - sys_read\n               - 52.80% vfs_read\n                  - 52.22% __vfs_read\n                     - seq_read\n                        - 50.43% proc_single_show\n                           - 50.38% proc_pid_status\n                              - 11.34% task_mem\n                                 + seq_printf\n                              + 6.99% seq_printf\n                              - 5.77% seq_put_decimal_ull\n                                   1.94% strlen\n                                 + 1.42% num_to_str\n                              - 5.73% cpuset_task_status_allowed\n                                 + seq_printf\n                              - 5.37% render_cap_t\n                                 + 5.31% seq_printf\n                              - 5.25% render_sigset_t\n                                   0.84% seq_putc\n                                0.73% __task_pid_nr_ns\n                              + 0.63% __lock_task_sighand\n                                0.53% hugetlb_report_usage\n                        + 0.68% _copy_to_user\n           1.10% number\n           1.05% seq_put_decimal_ull\n           0.84% vsnprintf\n           0.79% format_decode\n           0.73% syscall_return_via_sysret\n           0.52% 0xfffffe000003201b\n      + 20.95% __GI___libc_open\n      + 6.44% __getdents64\n      + 4.10% __close\r\nВидно, что только около 60% времени потрачено внутри системного вызова read(). Если же посмотреть профиль более внимательно, то обнаруживается, что 45% времени использовано внутри функций ядра seq_printf, seq_put_decimal_ull. А значит, конвертирование из бинарного формата в текстовый достаточно затратная операция. Что вызывает вполне обоснованный вопрос: а действительно ли нам нужен текстовый интерфейс, чтобы вытащить данные из ядра? Как часто пользователи хотят работать с сырыми данными? И почему утилитам top и ps приходится конвертировать эти текстовые данные обратно в бинарный вид?\r\nНаверное интересно было бы узнать, насколько быстрее был бы вывод, если бы использовались бинарные данные напрямую, и если бы не требовалось три системных вызова.\r\nПопытки создать такой интерфейс уже были. В 2004 пробовали использовать netlink движок.\r\n[0/2][ANNOUNCE] nproc: netlink access to /proc information (https://lwn.net/Articles/99600/)\n\nnproc is an attempt to address the current problems with /proc. In\nshort, it exposes the same information via netlink (implemented for a\nsmall subset).\r\nК сожалению, сообщество не проявило большого интереса к этой работе. Одна из последних попыток исправить ситуацию произошла два года назад.\r\n[PATCH 0/15] task_diag: add a new interface to get information about processes (https://lwn.net/Articles/683371/)\r\nИнтерфейс task-diag базируется на следующих принципах:\r\n\r\nТранзакционность: отправил запрос, получил ответ;\r\nФормат сообщений в виде netlink (такой же как у sock_diag интерфейса: бинарный и расширяемый);\r\nВозможность запросить информацию о множестве процессов в одном вызове;\r\nОптимизированная группировка атрибутов (любой атрибут в группе не должен увеличивать время ответа).\r\n\r\nЭтот интерфейс был презентован на нескольких конференциях. Его интегрировали в утилиты pstools, CRIU, а также David Ahern интегрировал task_diag в perf, в качестве эксперимента.\r\nСообщество разработчиков ядра заинтересовалось интерфейсом task_diag. Основным предметом обсуждений стал выбор транспорта между ядром и пространством пользователя. Начальная идея использования netlink сокетов была отклонена. Частично из-за нерешенных проблем в коде самого netlink движка, а частично потому, что многие думают, что интерфейс netlink был разработан исключительно для сетевой подсистемы. Потом было предложено использовать транзакционные файлы внутри procfs, то есть пользователь открывает файл, записывает в него сам запрос, а затем просто читает ответ. Как обычно, оказались и противники данного подхода. Решения, которое понравилось бы всем, пока не найдено.\r\nДавайте сравним производительность task_diag с procfs.\r\nУ task_diag движка есть тестовая утилита, которая удачно подходит для наших экспериментов. Предположим, что мы хотим запросить идентификаторы процесса и его права. Ниже приведен вывод для одного процесса: \r\n$ ./task_diag_all one  -c -p $$\npid  2305 tgid  2305 ppid  2299 sid  2305 pgid  2305 comm bash\nuid: 1000 1000 1000 1000\ngid: 1000 1000 1000 1000\nCapInh: 0000000000000000\nCapPrm: 0000000000000000\nCapEff: 0000000000000000\nCapBnd: 0000003fffffffff\r\nА теперь для всех процессов в системе, то есть тоже самое, что мы делали для эксперимента с procfs, когда читали файл /proc/pid/status:\r\n$ time ./task_diag_all all  -c\n\nreal    0m0.048s\nuser    0m0.001s\nsys 0m0.046s\r\nВсего лишь 0.05 секунды потребовалось, чтобы получить данные для построения дерева процессов. А с procfs требовалось 0.177 секунды только на открытие одного файла для каждого процесса, причем без чтения данных.\r\nВывод perf для task_diag интерфейса:\r\n-   82.24%     0.00%  task_diag_all  [kernel.vmlinux]            [k] entry_SYSCALL_64_fastpath\n   - entry_SYSCALL_64_fastpath\n      - 81.84% sys_read\n           vfs_read\n           __vfs_read\n           proc_reg_read\n           task_diag_read\n         - taskdiag_dumpit\n            + 33.84% next_tgid\n              13.06% __task_pid_nr_ns\n            + 6.63% ptrace_may_access\n            + 5.68% from_kuid_munged\n            - 4.19% __get_task_comm\n                 2.90% strncpy\n                 1.29% _raw_spin_lock\n              3.03% __nla_reserve\n              1.73% nla_reserve\n            + 1.30% skb_copy_datagram_iter\n            + 1.21% from_kgid_munged\n              1.12% strncpy   \r\nВ самом листинге нет ничего интересного, кроме факта, что здесь нет очевидных функций, подходящих для оптимизации.\r\nПосмотрим на вывод perf при чтении информации обо всех процессах в системе:\r\n $ perf trace -s ./task_diag_all all -c  -q\n\n Summary of events:\n\n task_diag_all (54326), 185 events, 95.4%\n\n   syscall            calls    total       min       avg       max      stddev\n                               (msec)    (msec)    (msec)    (msec)        (%)\n   --------------- -------- --------- --------- --------- ---------     ------\n   read                  49    40.209     0.002     0.821     4.126      9.50%\n   mmap                  11     0.051     0.003     0.005     0.007      9.94%\n   mprotect               8     0.047     0.003     0.006     0.009     10.42%\n   openat                 5     0.042     0.005     0.008     0.020     34.86%\n   munmap                 1     0.014     0.014     0.014     0.014      0.00%\n   fstat                  4     0.006     0.001     0.002     0.002     10.47%\n   access                 1     0.006     0.006     0.006     0.006      0.00%\n   close                  4     0.004     0.001     0.001     0.001      2.11%\n   write                  1     0.003     0.003     0.003     0.003      0.00%\n   rt_sigaction           2     0.003     0.001     0.001     0.002     15.43%\n   brk                    1     0.002     0.002     0.002     0.002      0.00%\n   prlimit64              1     0.001     0.001     0.001     0.001      0.00%\n   arch_prctl             1     0.001     0.001     0.001     0.001      0.00%\n   rt_sigprocmask         1     0.001     0.001     0.001     0.001      0.00%\n   set_robust_list        1     0.001     0.001     0.001     0.001      0.00%\n   set_tid_address        1     0.001     0.001     0.001     0.001      0.00%\r\nДля procfs нам нужно выполнить более 150000 системных вызовов, чтобы вытащить информацию о всех процессах, а для task_diag — чуть более 50.\r\nПосмотрим на реальные ситуации из жизни. Например, мы хотим вывести дерево процессов вместе с аргументами командной строки для каждого. Для этого нам необходимо вытащить pid процесса, pid его родителя и непосредственно сами аргументы командной строки.\r\nДля интерфейса task_diag программа отправляет один запрос, чтобы получить все параметры разом:\r\n$ time ./task_diag_all all  --cmdline -q\n\nreal    0m0.096s\nuser    0m0.006s\nsys 0m0.090s\r\nДля оригинального procfs нам необходимо читать /proc//status and /proc//cmdline у каждого процесса:\r\n$ time ./task_proc_all status\ntasks: 50278\n\nreal    0m0.463s\nuser    0m0.030s\nsys 0m0.427s\r\n$ time ./task_proc_all cmdline\ntasks: 50281\n\nreal    0m0.270s\nuser    0m0.028s\nsys 0m0.237s\r\nНетрудно заметить, что task_diag в 7 раз быстрее procfs (0.096 против 0.27 + 0.46). Обычно улучшение производительности на несколько процентов уже хороший результат, а тут скорость увеличилась почти на порядок.\r\nСтоит также упомянуть, что создание внутренних объектов ядра тоже сильно влияет на производительность. Особенно в случае, когда подсистема памяти под сильной нагрузкой. Сравним количество созданных объектов для procfs и task_diag:\r\n$ perf trace --event 'kmem:*alloc*'  ./task_proc_all status 2>&1 | grep kmem | wc -l\n58184\n$ perf trace --event 'kmem:*alloc*'  ./task_diag_all all -q 2>&1 | grep kmem | wc -l\n188\r\nА также надо выяснить сколько создается объектов при запуске простого процесса, например утилиты true:\r\n$ perf trace --event 'kmem:*alloc*'  true 2>&1 | wc -l\n94\r\nProcfs создает в 600 раз больше объектов, чем task_diag. Это одна из причин, почему procfs работает так плохо, когда сильная нагрузка по памяти. Хотя бы поэтому стоит ее оптимизировать.\r\nНадеемся, что статья привлечёт больше разработчиков к оптимизации состояния procfs подсистемы ядра.\r\nОгромная благодарность David Ahern, Andy Lutomirski, Stephen Hemming, Oleg Nesterov, W. Trevor King, Arnd Bergmann, Eric W. Biederman и многим другим, кто помогал разрабатывать и улучшать task_diag интерфейс.\r\nСпасибо cromer и k001 за помощь в написании этой статьи.\r\nСсылки\r\n\r\nhttps://github.com/avagin/linux-task-diag/tree/v4.16-task-diag-20180427/tools/testing/selftests/task_diag\r\nhttps://lwn.net/Articles/685791/\r\nhttps://www.slideshare.net/KirKolyshkin/time-to-rethink-proc\r\nhttps://www.slideshare.net/kolyshkin/speeding-up-ps-and-top\r\nhttps://blog.linuxplumbersconf.org/2016/ocw/system/presentations/4599/original/Netlink-issues.pdf\r\n",
            "images": [
                "https://habrastorage.org/getpro/habr/post_images/7c7/55c/f6b/7c755cf6b80f5b20ab194e548c3c99be.jpg"
            ]
        },
        {
            "title": "Оракулы, или почему смарт-контракты всё ещё не изменили мир?",
            "text": "Для тех, кто интересуется темой смарт-контрактов, ответ на вопрос, заданный в заголовке, лежит на поверхности: на сегодняшний день контракты не имеют достоверного и полного источника информации о происходящем в реальном мире. Вследствие этого складывается прескверная ситуация: мы можем описать в смарт-контракте сложную логику, а блокчейн обеспечит нам её безоговорочное исполнение. И вот, казалось бы, мы в шаге от того, чтобы избавиться от необходимости в третьей стороне при заключении договоров — именно это имелось в виду под словами «изменить мир» в заголовке. Однако любой логике, описывающей процессы реального мира, нужно знать, что в этом мире происходит. Таким образом, от «революции доверия» нас отделяет последняя преграда в виде отсутствия поставщиков информации или оракулов, как их называют в мире смарт-контрактов. Решение этой задачи дало бы колоссальный импульс распространённости и применимости смарт-контрактов. В противном случае эта технология рискует навсегда остаться лишь площадкой для реализации ICO.\r\n\r\n\r\n\r\nСпособности, не находящие применения, превращаются в ничто. \r\nСтен Надольный\r\n\r\nОракулы\r\nОракул — это поставщик информации, который по запросу контракта предоставляет из оффчейн мира достоверные данные, необходимые для корректной работы контракта. Основные требования к оракулу — это достоверность и полнота предоставляемой информации. Здесь под достоверностью подразумевается возможность подтвердить/проверить валидность данных, а под полнотой — способность предоставлять данные о широком круге событий из реального мира. Отметим отдельно, что оракул — это не источник информации, это именно её поставщик в блокчейн. Таким образом, выбор источника информации — это один из ключевых параметров оракула, ведь для того, чтобы оракул был достоверным и полным, источник тоже должен быть достоверным и полным (об источниках поговорим в следующем разделе).\r\n\r\n\r\n\r\nНачнем со свойства достоверности оракула. На сегодняшний день существует два основных подхода к достижению достоверности оракулов. Первый — это консенсус оракулов. Как следует из названия, в этом подходе используется консенсус нескольких независимых валидаторов. Главная проблема этого подхода (с точки зрения достоверности) — в создании сети независимых валидаторов. С одной стороны, если мы будем выбирать/назначать участников консенсуса (оракулов), то они будут зависимы от механизма выбора/назначения. Таким образом, централизация сохранится, хотя, конечно, в меньшей степени и в другом обличии. С другой стороны, если участником консенсуса может стать любой желающий, то система становится уязвимой к Sybil-атаке. Кроме того, существует мнение, что компрометировать (взломать, подкупить) несколько мелких участников консенсуса может быть легче, чем компрометировать одного крупного валидатора, так как у крупного игрока меры безопасности значительно серьезней, а репутационные издержки значительно выше.\r\n\r\nКомпания Oraclize предоставляет альтернативное консенсусу оракулов решение: пользователь сам выбирает источник информации в сети Internet. А для доказательства корректной работы оракула используются TLSNotary-доказательства. Это криптографические доказательства того, что данные, полученные из выбранного источника, переданы смарт-контракту в неизмененном виде.\r\n\r\n\r\n\r\nНа данный момент проверить эти доказательства можно в интернете, используя сетевой монитор для Ethereum (на момент написания статьи работает нестабильно). В будущем планируется реализовать возможность проверки доказательств TLSNotary непосредственно контрактом в сети Ethereum.\r\n\r\nВажно отметить, что у обоих подходов есть проблема доверия источнику/-кам информации: оба они в какой-то степени гарантируют нам честность передачи данных от источника к контракту, однако не гарантируют честность источника (даже если мы сами его выбрали).\r\n\r\nИсточники информации\r\nВ начале этого раздела затронем тему полноты предоставляемых оракулом данных. Достижение полноты значит расширение круга источников информации, а это влечет за собой еще большие вопросы к достоверности этих данных. Рассмотрим два простых примера: если вашему контракту необходима информация о текущем курсе ETH/USD, то в качестве источников можно рассматривать крупные криптовалютные биржи, консенсус которых будет достаточно достоверным. А в случае, если контракту необходимо знать, горит ли свет в вашей спальне, найти независимых очевидцев будет крайне сложно. Можно использовать физический источник, например, камеру в спальне, однако при желании её легко обмануть: наденьте на камеру мешок, и в вашей спальне для неё будет всегда темно. Таким образом, при увеличении полноты предоставляемой оракулом информации проблема поиска достоверных источников встает еще более остро.\r\n\r\nСамый естественный источник информации — централизованный. К такому подходу мы привыкли в обычной жизни: новости узнаем на любимом сайте, курс доллара — на сайте ЦБ. Большинство из нас слепо верит этим централизованным источникам, и эта вера чаще всего оправдана, ведь репутационные издержки для таких крупных компаний превышают потенциальную выгоду, которую можно извлечь, предоставив вам ложную информацию. Тут есть два «но». Во-первых, достоверность: даже имея дело с надежным централизованным источником, мы все еще оперируем верой, а не знанием. Во-вторых, что более важно, полнота: использование централизованного источника можно считать надежным подходом только для узкого круга резонансных событий.\r\n\r\nПервый способ обойти недостатки централизованного источника — использовать консенсус источников. Подобный подход мы уже обсуждали выше, когда говорили о консенсусе оракулов. Как и в случае с оракулами, этот подход улучшает и достоверность, и полноту предоставляемой информации, однако его положительный эффект ограничен и имеет свои недостатки (см. предыдущий раздел). \r\n\r\nЕще один подход к решению проблемы источников информации — это косвенный метод. Идея заключается в том, чтобы извлекать информацию об интересующем нас событии из косвенных источников. \r\n\r\n\r\n\r\nЭти источники будут разными для каждого вида событий: для температуры в Москве — фото из инстаграма с соответствующей геопозицией и датой, для результата матча — посты в социальных сетях с соответствующими тегами и датой, и т.д. Успехи последних лет в области машинного обучения, вероятно, позволят нам с приемлемой точностью определять исходы прошедших событий по косвенным источникам. Какие модели машинного обучения для этого применимы, какой будет точность, независимы ли косвенные источники — все эти вопросы должны рассматриваться для каждого конкретного события отдельно, а факт их разрешимости и будет критерием применимости косвенного метода для этого события. \r\n\r\nДля относительно простых задач, вроде определения результата матча по достаточной выборке постов любителей спорта, эти вопросы кажутся решаемыми. Предполагается, что контракт будет обращаться к узлу, на котором производятся вычисления (извлечение прогноза из косвенных источников). Достоверность вычислений предлагается подтверждать криптографически, как это реализовано, например, в проекте Golem.\r\n\r\n\r\n\r\nЭтот подход — второй шаг в сторону полноты оракулов. Это еще не про свет в спальне, но уже про погоду, про результаты выборов, про успешность запуска Falcon Heavy.\r\n\r\nДля полноты картины источников информации затронем тему рынков предсказаний, таких как Augur. Рынок использует «мудрость толпы» для предсказания будущих событий. Пользователи предсказывают возможный исход этих событий, покупая доли вознаграждения за правильно угаданный результат (победители разделят призовой фонд пропорционально размерам своих ставок). Таким образом, этот подход подразумевает экономическую мотивацию для участников предсказания: за правильное предсказание пользователь получает вознаграждение, а в случае неправильного теряет вложенные средства. Прогноз в данном случае — это средневзвешенное ожидание всех пользователей. Использование рынков предсказаний довольно сильно увеличивает полноту предоставляемой информации, ведь предсказывать можно что угодно (если найдется достаточно желающих), а достоверность обеспечивает экономическая мотивация участников предсказания. \r\n\r\nОднако не все так радужно, как может показаться на первый взгляд. Во-первых, предсказание — это лишь ожидание участников рынка (можно привести много примеров событий, наступления которых никто не ожидал). Во-вторых, в такой модели возможны манипуляции предсказанием, если издержки на изменение предсказания на ложное меньше, чем прибыль от неправильной работы контракта. Например, если в контракте предполагается крупная выплата в случае события A, а факт происхождения этого события определяет рынок предсказаний с небольшим оборотом средств, то злоумышленник может сфальсифицировать событие А, потратив лишь часть полученной выгоды на манипуляцию предсказанием.\r\n\r\nЗаключение\r\nЗначимость оракулов для технологии смарт-контрактов трудно переоценить. Оракул служит поставщиком информации от источника к контракту. И если существующие на сегодняшний день решения обеспечивают достаточно надежную передачу этой информации, то проблема с её изначальной достоверностью до сих пор остается нерешённой. Создание/выбор достоверных и полных источников информации – это тот последний рубеж, который отделяет смарт-контракты от повсеместного распространения. Учитывая активное развитие блокчейн-технологий, можно рассчитывать на хотя бы частичное преодоление этого рубежа в ближайшие годы.",
            "images": [
                "https://habrastorage.org/webt/jb/pq/i5/jbpqi5gccl28z4ywi5lxo86st8o.jpeg",
                "https://habrastorage.org/webt/qp/ux/ti/qpuxtimrmzkj0z7ym4ku1sz7xmy.jpeg",
                "https://habrastorage.org/webt/d2/bi/br/d2bibr-en41kmqiyvwega_meej0.jpeg",
                "https://habrastorage.org/webt/n_/wo/xo/n_woxozjz8uwgxufk1q9pjdfr-s.jpeg",
                "https://habrastorage.org/webt/lo/27/m-/lo27m-iwvkfk_iiuz5fclf-pvby.jpeg"
            ]
        }
    ]
}